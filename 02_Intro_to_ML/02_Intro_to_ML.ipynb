{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/MScEcologyAndDataScienceUCL/BIOS0032_AI4Environment/blob/main/02_Intro_to_ML/02_Intro_to_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39466540",
   "metadata": {},
   "source": [
    "# Week 2: Introduction to Machine Learning\n",
    "\n",
    "In this week, we will get a hands-on experience with the fundamental concepts of Machine Learning\n",
    "(ML)! 😃🤖\n",
    "\n",
    "## Contents\n",
    "\n",
    "0. [Introduction](#0-introduction)\n",
    "1. [Data and Problem Statement](#1-data-and-problem-statement)\n",
    "2. [Unsupervised Learning A: Clustering](#2-unsupervised-learning-a-clustering)\n",
    "3. [Unsupervised Learning B: Dimensionality Reduction](#3-unsupervised-learning-b-dimensionality-reduction)\n",
    "4. [Supervised Learning](#4-supervised-learning)\n",
    "5. [Exercise: Putting it all Together](#5-exercise-putting-it-all-together)\n",
    "6. [Regression](#6-regression)\n",
    "7. [Conclusion](#7-conclusion)\n",
    "\n",
    "\n",
    "## Notes\n",
    "\n",
    "- If a line starts with the fountain pen symbol (🖌️), it asks you to implement a code part or\n",
    "answer a question.\n",
    "- Lines starting with the light bulb symbol (💡) provide important information or tips and tricks.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Introduction\n",
    "\n",
    "Let us briefly recap the idea of machine learning:\n",
    "\n",
    "> \"ML is teaching computers how to perform a task without having to explicitly program them to do\n",
    "> it.\"\n",
    "\n",
    "To do so, we need the following ingredients:\n",
    "* Task: for example, classifying species of butterflies in images\n",
    "* Data: butterfly images (input), annotations of which species each image depicts (label)\n",
    "* Model: a function that predicts our desired output based on the input\n",
    "\n",
    "Our aim then is to train the model on given data to optimally fulfil the task.\n",
    "\n",
    "Other examples that could be formulated as ML tasks:\n",
    "* Predicting bat species from audio recordings\n",
    "* Predicting bat behaviours from audio recordings\n",
    "* Estimating the average global temperature from greenhouse gas emissions\n",
    "* Mapping land cover from satellite imagery\n",
    "* Predicting under which environmental conditions (temperature, precipitation, _etc._) we observe\n",
    "  which species – we'll see this below.\n",
    "\n",
    "\n",
    "Basically, any process where we can observe _relationships_ within data is a candidate for ML.\n",
    "Whether or not ML makes sense, and which models do and do not, are completely different questions.\n",
    "\n",
    "\n",
    "### 0.1 ML Workflow\n",
    "\n",
    "Training an ML model involves the following steps:\n",
    "\n",
    "![ml workflow](https://github.com/MScEcologyAndDataScienceUCL/BIOS0032_AI4Environment/blob/main/02_Intro_to_ML/ml_workflow.png?raw=true)\n",
    "\n",
    "Notes:\n",
    "* It's not a linear process, but an _iterative_ one: you usually have to go back multiple times to\n",
    "  review what's happening.\n",
    "* This is because you cannot expect an ML model to figure out everything by itself. It's no\n",
    "  witchcraft, but simply an **exploitation of patterns** that correlate with what you want to\n",
    "  predict.\n",
    "* Related to this: ML models are only as good as the data (think about the last part of today's\n",
    "  lecture). This also applies to the biggest deep learning models out there. Rubbish in, rubbish\n",
    "  out.\n",
    "\n",
    "Let's see it in action!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d11450",
   "metadata": {},
   "source": [
    "## 1. Data and Problem Statement\n",
    "\n",
    "Today, we will learn, and apply, concepts of ML with application to **Species Distribution\n",
    "Modelling (SDM)**.\n",
    "\n",
    "Biotic species all have their _environmental niche_ – that is, an optimal combination of properties\n",
    "of the world's surroundings that sustains the species across generations. For example, a polar bear\n",
    "might need different temperatures than a Kookaburra, while a mountain goat can only be found in\n",
    "rugged terrain. Oftentimes, it's a combination of factors that determines _habitat suitability_, and\n",
    "SDMs try to predict this.\n",
    "\n",
    "To do so, most SDMs take environmental conditions as input (\"covariates\") and are trained to predict\n",
    "the presence/absence of a species based on observations. Cast into an ML framework, covariates are\n",
    "our input features and observations our ground truth. Since we predict across multiple species and\n",
    "have a target variable, we are performing **supervised classification**.\n",
    "\n",
    "\n",
    "\n",
    "The dataset we'll be using in this exercise comes from the following paper:\n",
    "> Winner, K., Ingenloff, K., Sandall, E., Sica, YV, Marsh, C., Cohen, J., Ranipeta, A., Killion, A.,\n",
    "> Jetz, W.: _High Resolution Species Distribution Models of North American Biodiversity_. In\n",
    "> preparation.\n",
    "\n",
    "We'll be using a subset of ten mammalian species occurrences over North America.\n",
    "\n",
    "\n",
    "Let us first load the _observations_. They come from GBIF\n",
    "([10.15468/DL.ZP2JZF](https://www.gbif.org/occurrence/download/0291299-200613084148143)) and have\n",
    "been pre-processed already, including removal of outliers and duplicates, and binning into $1km^2$\n",
    "resolution grid cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58b058f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "obs = pd.read_csv('https://raw.githubusercontent.com/MScEcologyAndDataScienceUCL/BIOS0032_AI4Environment/refs/heads/main/data/north_american_mammals/locations.csv')\n",
    "\n",
    "obs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many species and how many data points per species we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.histplot(obs, x='species')\n",
    "_ = plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fee420c",
   "metadata": {},
   "source": [
    "We can visualise these points on a map, too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39a4fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter_mapbox(obs,\n",
    "                        lat='lat',\n",
    "                        lon='lon',\n",
    "                        title='Observations',\n",
    "                        hover_name='species',\n",
    "                        color='species',\n",
    "                        height=600,\n",
    "                        width=800,\n",
    "                        zoom=2)\n",
    "fig.update_layout(mapbox_style='open-street-map')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577fb0a6",
   "metadata": {},
   "source": [
    "What if we could predict where which species occurs, based on environmental conditions? That is the\n",
    "key idea of an SDM!\n",
    "\n",
    "But how do we measure, and represent, environmental conditions? And: which kinds of descriptors are\n",
    "appropriate for the task?\n",
    "\n",
    "This happens to be a challenge in itself, and I invite you to think about \"right\" and \"wrong\" ideas.\n",
    "For now, let us load a few of them that have been prepared for you from the following sources:\n",
    "* `meanAnnualTemp`: mean annual air temperature [CHELSA]\n",
    "* `seasonalityPrecip`: precipitation seasonality [CHELSA]\n",
    "* `accumPrecip`: accumulated precipitation on growing season days [CHELSA]\n",
    "* `cloudCoverAnnualVar`: cloud cover intra-annual variation [EarthEnv]\n",
    "* `topoRugged`: topographic ruggedness index [EarthEnv]\n",
    "* `summerEVI`: mean summer EVI (Jun-Aug) [MODIS]\n",
    "* `winterEVI`: mean winter EVI (Nov-Feb) [MODIS]\n",
    "\n",
    "Sources:\n",
    "* [CHELSA] https://chelsa-climate.org/\n",
    "* [EarthEnv] https://www.earthenv.org/\n",
    "* [MODIS] https://lpdaac.usgs.gov/products/mod13q1v006/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5be0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load covariates\n",
    "cov = pd.read_csv('https://raw.githubusercontent.com/MScEcologyAndDataScienceUCL/BIOS0032_AI4Environment/refs/heads/main/data/north_american_mammals/covariates.csv')\n",
    "\n",
    "# print first few rows\n",
    "cov.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3f9b1c",
   "metadata": {},
   "source": [
    "You can see that both the covariates and observations have a column named `id` that is unique for\n",
    "each data point. We can _join_ them together based on this field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5acb18ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge (join) both data frames based on \"id\" column\n",
    "data = pd.merge(obs, cov, on='id')\n",
    "\n",
    "# remove invalid (NaN) values\n",
    "data = data.dropna()\n",
    "\n",
    "data.head()\n",
    "\n",
    "# keep track of all covariate names\n",
    "cov_cols = list(frozenset(cov.columns).difference(frozenset(['id', 'lon', 'lat', 'species'])))\n",
    "\n",
    "# separate data into features (X) and labels (y)\n",
    "X = data[cov_cols]\n",
    "y = data['species']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2b039d",
   "metadata": {},
   "source": [
    "💡 If you are curious how to extract these covariate values per location: we will learn about this\n",
    "in Sessions 8 and 9."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d30f52",
   "metadata": {},
   "source": [
    "We basically now have a dataset together that allows us to train, and evaluate, many types of ML\n",
    "models!\n",
    "\n",
    "Recall terminology from the lecture:\n",
    "* Data point: a single row in the data frame\n",
    "* $X$: features, descriptors, covariates (characteristics per data point of the environment)\n",
    "* $y$: label, target, ground truth (here: species name, if we want to predict which one we observed)\n",
    "\n",
    "Let's do some ML!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69ec5cd",
   "metadata": {},
   "source": [
    "## 2. Unsupervised Learning A: Clustering\n",
    "\n",
    "We will commence by taking a look at unsupervised learning. Here, our aim is to identify\n",
    "**patterns** in the data $X$ without trying to predict a label – there is no $y$ (no species) here,\n",
    "we only look at covariates.\n",
    "\n",
    "\n",
    "Let us first visualise some of the features (covariates) in a scatter plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cddd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just run this code cell, but otherwise ignore it (no need to understand what's going on)\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "\n",
    "def plot_feature_space(dataframe,\n",
    "                       axis_names=cov_cols,\n",
    "                       colour_by='species'):\n",
    "    w_x = widgets.Dropdown(description='x Axis:', options=axis_names, value=axis_names[0])\n",
    "    w_y = widgets.Dropdown(description='y Axis:', options=axis_names, value=axis_names[1])\n",
    "    w_c = None\n",
    "    if not isinstance(colour_by, str):\n",
    "        w_c = widgets.Dropdown(description='colour by:', options=colour_by, value=colour_by[-1])\n",
    "\n",
    "    def onchange(_):\n",
    "        plt.clf()\n",
    "        plt.figure(figsize=(10,8))\n",
    "        clear_output(wait=False)\n",
    "        out = widgets.Output()\n",
    "        out.append_display_data(w_x)\n",
    "        out.append_display_data(w_y)\n",
    "        if w_c is not None:\n",
    "            out.append_display_data(w_c)\n",
    "            hue = w_c.value\n",
    "        else:\n",
    "            hue = colour_by\n",
    "        sns.scatterplot(dataframe,\n",
    "                        x=w_x.value,\n",
    "                        y=w_y.value,\n",
    "                        hue=hue)\n",
    "        display(out)\n",
    "\n",
    "    w_x.observe(onchange)\n",
    "    w_y.observe(onchange)\n",
    "    if w_c is not None:\n",
    "        w_c.observe(onchange)\n",
    "    onchange(None)\n",
    "\n",
    "plot_feature_space(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba5b8cb",
   "metadata": {},
   "source": [
    "🖌️ Play around with the two dropdown menus to visualise different combinations of features\n",
    "(covariates).\n",
    "\n",
    "Can you already see some patterns?\n",
    "\n",
    "Perhaps there are combinations of features that are better suited to discriminate between species\n",
    "than others?\n",
    "\n",
    "Is there a combination of two features that allows full separation of all species?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed22fe3e",
   "metadata": {},
   "source": [
    "### 2.1 k-Means\n",
    "\n",
    "A first type of unsupervised learning is clustering, where we try to find **natural groupings** in\n",
    "the data. This is useful for many types of tasks, such as data exploration and sanity checks (for\n",
    "example, we would expect species living in similar environments to be close together in _feature\n",
    "space_).\n",
    "\n",
    "There are multiple ways to do so, but the most typical algorithm is called $k$-Means.\n",
    "\n",
    "🖌️ Read up Scikit-learn's [k-Means implementation\n",
    "documentation](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) and\n",
    "see how it works. Take a particular look at the \"Examples\" section and the methods it offers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e01ecf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# initiate new clustering algorithm\n",
    "k_means = KMeans(n_clusters=5)\n",
    "\n",
    "# fit model to data\n",
    "k_means.fit(X)\n",
    "\n",
    "# predict cluster assignments\n",
    "y_pred = k_means.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few things have happened in the code cell above:\n",
    "1. We imported the k-Means algorithm implementation from scikit-learn.\n",
    "2. Next, we created a new k-Means _instance_ (`k_means = ...`) and defined how it should behave.\n",
    "   That instance has not yet seen any of our data, though.\n",
    "3. We then _fit_ the model to our data, `X`. Here is where the **learning** takes place!\n",
    "4. Finally, our model has learnt the clusters of our data, so we can use it to obtain\n",
    "   **predictions**. More specifically, by calling the `.predict()` function, we can feed it with\n",
    "   data points of the same type of features and the model will return which of its clusters each\n",
    "   data point belongs to.\n",
    "\n",
    "You will see down below that all Scikit-learn models operate along very similar principles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now visualise cluster assignments in _feature space_..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_kmeans = data.copy()\n",
    "pred_kmeans['cluster_index'] = y_pred.astype(str)\n",
    "\n",
    "plot_feature_space(pred_kmeans, colour_by=['species', 'cluster_index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and in geographic space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise cluster assignments in geographic space\n",
    "fig = px.scatter_mapbox(pred_kmeans,\n",
    "                        lat='lat',\n",
    "                        lon='lon',\n",
    "                        title='Observations clustered',\n",
    "                        hover_name='species',\n",
    "                        color='cluster_index',\n",
    "                        height=600,\n",
    "                        width=800,\n",
    "                        zoom=2)\n",
    "fig.update_layout(mapbox_style='open-street-map')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did that work well? Can you now see some patterns in either feature and/or geographic space? Why,\n",
    "respectively why not?\n",
    "\n",
    "\n",
    "#### Hyperparameters\n",
    "\n",
    "Recall from the lecture what a hyperparameter is: a property of the ML algorithm that is not learnt\n",
    "from the data $X$ itself, _i.e._, we set it _by hand_.\n",
    "\n",
    "$k$-Means has one key hyperparameter: $k$, the number of clusters.\n",
    "\n",
    "🖌️ Go back up and change this hyperparameter down and up. What happens? Is there an optimum?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many other clustering algorithms available, including some which try to estimate the\n",
    "optimal number of clusters from the data. Make sure to check out [clustering algorithms in\n",
    "Scikit-learn](https://scikit-learn.org/stable/api/sklearn.cluster.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Unsupervised Learning B: Dimensionality Reduction\n",
    "\n",
    "From the scatter plots above, you can see that they quickly become unwieldy: we can only\n",
    "realistically visualise two covariates at the same time, three already can become quite ambiguous.\n",
    "However, the clustering exercise showed us that data points tend to be grouped together somewhat.\n",
    "Wouldn't it be great if we could \"compress\" all of these patterns into just a few, say two,\n",
    "dimensions that represent points in their feature space distance more visibly?\n",
    "\n",
    "This is exactly what dimensionality reduction tries to achieve!\n",
    "\n",
    "It's a useful technique for visualisation, but sometimes also for pre-processing of features, in\n",
    "cases where there are too many of them for a downstream model to process.\n",
    "\n",
    "\n",
    "### 3.1 PCA\n",
    "\n",
    "The first dimensionality reduction method we will take a look at is **Principal Component Analysis\n",
    "(PCA)**. PCA applies a _linear transformation_, a _rotation_ of the feature space, so that the first\n",
    "_component_ contains as much of the variance as possible.\n",
    "\n",
    "Let's first start with a toy example. Suppose we have data as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x1 = np.random.randn(400)\n",
    "x2 = 0.7*x1 + 0.5 * np.random.randn(400)\n",
    "\n",
    "ax = sns.scatterplot(x=x1, y=x2)\n",
    "ax.set_xlim([-3, 3])\n",
    "ax.set_ylim([-3, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Watch what happens when we apply PCA to these two features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import PCA from scikit-learn\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# combine the two toy features\n",
    "toy_data = np.stack((x1, x2), 1)\n",
    "\n",
    "# fit a PCA and transform the data to obtain principal components\n",
    "pca = PCA().fit(toy_data)\n",
    "components = pca.transform(toy_data)\n",
    "\n",
    "# visualise the two principal components\n",
    "ax = sns.scatterplot(x=components[:,0],\n",
    "                     y=components[:,1])\n",
    "ax.set_xlim([-3, 3])\n",
    "ax.set_ylim([-3, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suddenly, all the data points are distributed along the first (x) axis. In other words, the first\n",
    "component captures most of the variance! Their _relative_ distribution is still the same.\n",
    "\n",
    "By default, PCA returns as many components as there are dimensions in the data. However, what often\n",
    "happens under very high-dimensional data is that the first few components contain all of the\n",
    "variance (information), while the remaining ones only capture residual noise. Let's see this in\n",
    "action on our environmental covariates from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new PCA object\n",
    "pca = PCA().fit(X)\n",
    "components = pca.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = [f'component {c+1}' for c in range(X.shape[1])]\n",
    "\n",
    "if not isinstance(components, pd.DataFrame):\n",
    "    components = pd.DataFrame(components, columns=colnames)\n",
    "    components['species'] = data['species']\n",
    "\n",
    "plot_feature_space(components, colnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA also calculates how much of the data's variance each principal component explains. We can plot\n",
    "this in descending order, from the first to the last component. This is called a **Scree plot**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(X.shape[1]), pca.explained_variance_ratio_, 'o-', linewidth=2, color='blue')\n",
    "plt.xlabel('Principal component')\n",
    "plt.ylabel('Explained variance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice a little bit of an \"elbow\" near the third to fourth PC? It's not as pronounced here, but this\n",
    "is usually where you'd make a cut – you would only use the first $n$ PCs up until this point for\n",
    "further analyses, as all the remaining ones mostly contain only noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 t-SNE\n",
    "\n",
    "As you have seen above, PCA was only somewhat able to condense the data variation effectively. We\n",
    "still see a lot of variance beyond the first two components, so clearly, PCA isn't as effective as\n",
    "could be for this dataset.\n",
    "\n",
    "The reason for this is that our environmental conditions show **non-linear interactions**. Remember\n",
    "that PCA just applies a rotation (see toy example)? That is a linear transformation; therefore, it\n",
    "doesn't suffice to represent our data properly. In some sense, PCA _underfits_ our data (yes, even\n",
    "unsupervised models can do that!). What can we do instead?\n",
    "\n",
    "\n",
    "There are in fact dimensionality reduction methods that operate non-linearly. The first one we will\n",
    "take a look at is called **t-Stochastic Neighbour Embedding (t-SNE)**. This works by representing\n",
    "data points on the Student-t distribution. Checkout the\n",
    "[paper](https://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf) where t-SNE was\n",
    "introduced, or this [blog](https://distill.pub/2016/misread-tsne/) for further information.\n",
    "\n",
    "\n",
    "Let's see what happens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import t-SNE mapping from scikit-learn\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# use t-SNE to project data to two dimensions\n",
    "tsne = TSNE(n_components=2,\n",
    "            init='pca',\n",
    "            learning_rate='auto')\n",
    "dimensions = tsne.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = [f'dimension {c+1}' for c in range(dimensions.shape[1])]\n",
    "\n",
    "if not isinstance(dimensions, pd.DataFrame):\n",
    "    dimensions = pd.DataFrame(dimensions, columns=colnames)\n",
    "    dimensions['species'] = data['species']\n",
    "\n",
    "plot_feature_space(dimensions, colnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you separate the data more clearly?\n",
    "\n",
    "Well, we can see some really interesting patterns, but it's not perfect.\n",
    "\n",
    "\n",
    "### 3.3 UMAP\n",
    "\n",
    "Let's try another method, Uniform Manifold Approximation and Projectin (UMAP). For this, we need to\n",
    "install the [umap-learn](https://umap-learn.readthedocs.io/en/latest/index.html) library first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "\n",
    "dimensions = UMAP(n_components=2).fit_transform(X)\n",
    "\n",
    "colnames = [f'dimension {c+1}' for c in range(dimensions.shape[1])]\n",
    "\n",
    "if not isinstance(dimensions, pd.DataFrame):\n",
    "    dimensions = pd.DataFrame(dimensions, columns=colnames)\n",
    "    dimensions['species'] = data['species']\n",
    "\n",
    "plot_feature_space(dimensions, colnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks different, but it's still not good.\n",
    "\n",
    "One reason we don't see good separation often is because methods like t-SNE and UMAP (and many other\n",
    "ML ones, especially deep learning) are influenced by the **magnitude of covariates**: if one\n",
    "covariate has particularly big positive and/or negative values, relative to the others, it can\n",
    "dominate the signal and bias the model.\n",
    "\n",
    "Luckily, we can resolve this problem through **data normalisation**. One of the most common means to\n",
    "do so is called **z-scoring**, and it works as follows:\n",
    "\n",
    "$$\\hat{x} = \\frac{x - mean(x)}{std(x)}$$\n",
    "\n",
    "Scikit-learn provides utilities to do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the StandardScaler from scikit-learn preprocessing module\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# standardise the data\n",
    "X_norm = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply UMAP again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = UMAP(n_components=2).fit_transform(X_norm)\n",
    "\n",
    "colnames = [f'dimension {c+1}' for c in range(dimensions.shape[1])]\n",
    "\n",
    "if not isinstance(dimensions, pd.DataFrame):\n",
    "    dimensions = pd.DataFrame(dimensions, columns=colnames)\n",
    "    dimensions['species'] = data['species']\n",
    "\n",
    "plot_feature_space(dimensions, colnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still not perfect, but better! We can start to see discernible clusters of species.\n",
    "\n",
    "This tells us that we can probably proceed with trying to predict which species has been observed\n",
    "under which feature combination. Since non-linear methods gave us the best results, it seems likely\n",
    "that we will also need a non-linear classifier to do so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Summary: Unsupervised Learning\n",
    "\n",
    "Unsupervised methods come in handy to get a first overview of the data, to preprocess it, and to\n",
    "identify patterns. They are thus very popular for exploratory analyses, including inference.\n",
    "\n",
    "But of course, they also have their limits. Any _semantic meaning_ you wish to assign to the data,\n",
    "such as a label class (species), can almost never be realistically uncovered by any of them.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Supervised Learning\n",
    "\n",
    "We have had an extensive look at our covariates (features) above. We have seen that some of the\n",
    "species tend to form clusters and are, to some degree, separable in our high-dimensional feature\n",
    "space. This is a good starting point, because it means that we can possibly learn to _exploit_ these\n",
    "_patterns_ in the data to predict a semantic concept: the species we have observed at each location.\n",
    "\n",
    "Enter: supervised learning. Now, we also have a **ground truth** (target, $y$) that we want to\n",
    "predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Concepts\n",
    "\n",
    "Let us first take a look at the task of supervised learning itself. For simplification and\n",
    "visualisation reasons, we will subset our data above to:\n",
    "1. Two species, the White-tailed antelope squirrel (_Ammospermophilus leucurus_) and the Reindeer\n",
    "   (_Rangifer tarandus_).\n",
    "2. Two covariates, mean annual temperature and precipitation seasonality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_subset = ['Ammospermophilus_leucurus', 'Rangifer_tarandus']\n",
    "covs_subset = ['meanAnnualTemp', 'seasonalityPrecip']\n",
    "\n",
    "data_subset = data[covs_subset + ['lat', 'lon', 'species']]\n",
    "data_subset = data_subset[data_subset['species'].isin(species_subset)]\n",
    "\n",
    "X_subset = data_subset[covs_subset]\n",
    "y_subset = data_subset['species']\n",
    "\n",
    "plot_feature_space(data_subset, covs_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks suspiciously... _separable_.\n",
    "\n",
    "Remember the key objective of a supervised model? It's prediction: given a new data point with\n",
    "covariate values, we want to predict which species has been observed there based on the experience\n",
    "(training data) we have, _i.e._, our observations and covariate values shown in the plot above.\n",
    "\n",
    "Let's add a new, previously unseen point to demonstrate this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a new test point with given covariate values\n",
    "test_point = pd.DataFrame({'meanAnnualTemp': [2800.0], 'seasonalityPrecip': [900.0]})\n",
    "\n",
    "\n",
    "plot_feature_space(data_subset, covs_subset)\n",
    "ax = sns.scatterplot(test_point, x='meanAnnualTemp', y='seasonalityPrecip', color='k', s=50)\n",
    "ax.annotate('test point',\n",
    "            (test_point.values[0,0] + 5, test_point.values[0,1] + 15),\n",
    "            xytext=(test_point.values[0,0] + 20, test_point.values[0,1] + 80),\n",
    "            fontsize=12,\n",
    "            color='k',\n",
    "            arrowprops={\n",
    "                \"width\": 1,\n",
    "                \"headwidth\": 6,\n",
    "                \"headlength\": 6,\n",
    "                \"edgecolor\": 'k',\n",
    "                \"facecolor\": 'k',\n",
    "            })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 $k$-Nearest Neighbour\n",
    "\n",
    "The first supervised classifier we will take a look at should be familiar to you from the lecture:\n",
    "$k$-Nearest Neighbour.\n",
    "\n",
    "As you have seen and the name suggests, it is based on finding the training points that are closest\n",
    "in feature space to our test point. To do so, we need to perform the following steps:\n",
    "1. Calculate distances between all training points and the test point.\n",
    "2. Select the top-$k$ training points with _smallest distance_.\n",
    "3. Assign label: most frequent training label (mode).\n",
    "\n",
    "\n",
    "First, let's think about distance. This should tell us, numerically, how similar two points are in\n",
    "feature space. The first and most intuitive idea is to use the _Euclidean_ distance (based on the\n",
    "Pythagorean theorem):\n",
    "\n",
    "![euclidean distance](https://upload.wikimedia.org/wikipedia/commons/5/55/Euclidean_distance_2d.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "dist = np.sqrt(np.sum((X_subset.values - test_point[covs_subset].values)**2, 1))\n",
    "\n",
    "\n",
    "# scatter plot with point sizes depending on their distance to test point\n",
    "sns.scatterplot(data_subset,\n",
    "                x=covs_subset[0],\n",
    "                y=covs_subset[1],\n",
    "                s=dist/6)\n",
    "sns.scatterplot(test_point, x='meanAnnualTemp', y='seasonalityPrecip', color='k', s=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find the closest training point: it's the one with minimum distance to the test point, or\n",
    "mathematically speaking, the \"argument of the minimum\" ($\\arg\\min$):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_point_index = np.argmin(dist)\n",
    "closest_point = X_subset.iloc[closest_point_index].values\n",
    "\n",
    "# visualise the closest point\n",
    "plot_feature_space(data_subset, covs_subset)\n",
    "ax = sns.scatterplot(test_point, x='meanAnnualTemp', y='seasonalityPrecip', color='k', s=50)\n",
    "ax.annotate('closest point',\n",
    "            (closest_point[0]-2, closest_point[1] + 15),\n",
    "            xytext=(closest_point[0] - 80, closest_point[1] + 120),\n",
    "            fontsize=12,\n",
    "            color='k',\n",
    "            arrowprops={\n",
    "                \"width\": 1,\n",
    "                \"headwidth\": 6,\n",
    "                \"headlength\": 6,\n",
    "                \"edgecolor\": 'k',\n",
    "                \"facecolor\": 'k',\n",
    "            })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks fair enough. With just this one point, the predicted label thus is the one of this\n",
    "closest point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = y_subset.iloc[closest_point_index]\n",
    "print(f'Predicted label: {y_hat}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "💡 We don't necessarily have to use Euclidean distance. Some feature spaces might be more easily\n",
    "separable with other metrics. See the [scikit-learn\n",
    "documentation](https://scikit-learn.org/1.5/modules/generated/sklearn.metrics.DistanceMetric.html)\n",
    "for other examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try another point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second test point\n",
    "test_point_2 = pd.DataFrame({'meanAnnualTemp': [2850.0], 'seasonalityPrecip': [120.0]})\n",
    "\n",
    "\n",
    "plot_feature_space(data_subset, covs_subset)\n",
    "ax = sns.scatterplot(test_point_2, x='meanAnnualTemp', y='seasonalityPrecip', color='k', s=50)\n",
    "ax.annotate('test point',\n",
    "            (test_point_2.values[0,0] + 5, test_point_2.values[0,1] + 15),\n",
    "            xytext=(test_point_2.values[0,0] + 20, test_point_2.values[0,1] + 80),\n",
    "            fontsize=12,\n",
    "            color='k',\n",
    "            arrowprops={\n",
    "                \"width\": 1,\n",
    "                \"headwidth\": 6,\n",
    "                \"headlength\": 6,\n",
    "                \"edgecolor\": 'k',\n",
    "                \"facecolor\": 'k'\n",
    "            })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you guess what will happen here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_2 = np.sqrt(np.sum((X_subset.values - test_point_2[covs_subset].values)**2, 1))\n",
    "\n",
    "closest_point_index_2 = np.argmin(dist_2)\n",
    "closest_point_2 = X_subset.iloc[closest_point_index_2].values\n",
    "\n",
    "y_hat_2 = y_subset.iloc[closest_point_index_2]\n",
    "print(f'Predicted label for second test point: {y_hat_2}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That does not seem right.\n",
    "\n",
    "Sure, the closest point in our training set has label _Rangifer tarandus_ – but it's the only one in\n",
    "quite a distance. What if this is a measurement or data error?\n",
    "\n",
    "You can see a problem with nearest neighbour right away: it's very susceptible to **noise** in the\n",
    "data. Then again, this training point could very well be a real one if the data isn't as separable\n",
    "as we hoped (_cf._ unsupervised learning part above). What can we do in this case?\n",
    "\n",
    "\n",
    "A first idea is to take more training samples into account when taking a decision. If you have\n",
    "guessed that this pertains to the $k$ in $k$-Nearest Neighbour, you are 100% right! If we take the\n",
    "top-$k$ instead of just the top-1 closest training point into account, we can \"iron out\" any small\n",
    "errors and artefacts in the dataset and possibly obtain a better-informed decision.\n",
    "\n",
    "We can do so by sorting the distances in ascending order and literally taking the first $k$\n",
    "elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set k in advance (hyperparameter!)\n",
    "k = 3\n",
    "\n",
    "\n",
    "# sort distances. We're not interested in the distance values at this point, only the index of the\n",
    "# top-k points, so we can directly use NumPy's argsort function\n",
    "dist_2_indices = np.argsort(dist_2)\n",
    "\n",
    "# take the top-k\n",
    "closest_point_indices_topk = dist_2_indices[:k]\n",
    "closest_points_topk = data_subset.iloc[closest_point_indices_topk]\n",
    "\n",
    "# plot\n",
    "plot_feature_space(data_subset, covs_subset)\n",
    "sns.scatterplot(test_point_2, x='meanAnnualTemp', y='seasonalityPrecip', color='k', s=50)\n",
    "sns.scatterplot(closest_points_topk, x='meanAnnualTemp', y='seasonalityPrecip', facecolor='none', edgecolor='k', linewidth=1, s=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the predicted label becomes the mode of the top-$k$ closest points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_topk = closest_points_topk['species'].mode().values[0]\n",
    "\n",
    "print(f'Predicted label for k={k}: {y_hat_topk}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks better!\n",
    "\n",
    "Scikit-learn has an implementation of $k$-Nearest Neighbour available for us to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# create a model instance\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "# fit model with data\n",
    "knn.fit(X_subset, y_subset)\n",
    "\n",
    "# predict test point\n",
    "y_hat_2_sklearn = knn.predict(test_point_2)\n",
    "\n",
    "print(f'Predicted label for k={k} by scikit-learn implementation: {y_hat_2_sklearn[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the official implementation, we can also visualise its **decision boundary**.\n",
    "\n",
    "The following code cell does that – you don't need to understand how this works, just run it so that\n",
    "we have the function ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title plot decision boundary function definition\n",
    "\n",
    "# IGNORE: here we define functions to plot the decision boundary.\n",
    "# Their implementation is not relevant.\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "from sklearn.base import is_regressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import _safe_indexing\n",
    "from sklearn.utils.validation import _is_arraylike, _num_features\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "\n",
    "def _is_arraylike_not_scalar(array):\n",
    "    return _is_arraylike(array) and not np.isscalar(array)\n",
    "\n",
    "\n",
    "def _check_boundary_response_method(estimator, response_method):\n",
    "    has_classes = hasattr(estimator, \"classes_\")\n",
    "    if has_classes and _is_arraylike_not_scalar(estimator.classes_[0]):\n",
    "        msg = \"Multi-label and multi-output multi-class classifiers are not supported\"\n",
    "        raise ValueError(msg)\n",
    "\n",
    "    if has_classes and len(estimator.classes_) > 2:\n",
    "        if response_method not in {\"auto\", \"predict\"}:\n",
    "            msg = (\n",
    "                \"Multiclass classifiers are only supported when response_method is\"\n",
    "                \" 'predict' or 'auto'\"\n",
    "            )\n",
    "            raise ValueError(msg)\n",
    "        methods_list = [\"predict\"]\n",
    "    elif response_method == \"auto\":\n",
    "        methods_list = [\"decision_function\", \"predict_proba\", \"predict\"]\n",
    "    else:\n",
    "        methods_list = [response_method]\n",
    "\n",
    "    prediction_method = [getattr(estimator, method, None) for method in methods_list]\n",
    "    prediction_method = reduce(lambda x, y: x or y, prediction_method)\n",
    "    if prediction_method is None:\n",
    "        raise ValueError(\n",
    "            f\"{estimator.__class__.__name__} has none of the following attributes: \"\n",
    "            f\"{', '.join(methods_list)}.\"\n",
    "        )\n",
    "\n",
    "    return prediction_method\n",
    "\n",
    "\n",
    "def plot_decision_boundary(\n",
    "    estimator,\n",
    "    X,\n",
    "    *,\n",
    "    grid_resolution=100,\n",
    "    eps=1.0,\n",
    "    plot_method=\"contourf\",\n",
    "    response_method=\"auto\",\n",
    "    xlabel=None,\n",
    "    ylabel=None,\n",
    "    ax=None,\n",
    "    **kwargs,\n",
    "):\n",
    "    if not grid_resolution > 1:\n",
    "        raise ValueError(\n",
    "            \"grid_resolution must be greater than 1. Got\" f\" {grid_resolution} instead.\"\n",
    "        )\n",
    "\n",
    "    if not eps >= 0:\n",
    "        raise ValueError(f\"eps must be greater than or equal to 0. Got {eps} instead.\")\n",
    "\n",
    "    possible_plot_methods = (\"contourf\", \"contour\", \"pcolormesh\")\n",
    "    if plot_method not in possible_plot_methods:\n",
    "        available_methods = \", \".join(possible_plot_methods)\n",
    "        raise ValueError(\n",
    "            f\"plot_method must be one of {available_methods}. \"\n",
    "            f\"Got {plot_method} instead.\"\n",
    "        )\n",
    "\n",
    "    num_features = _num_features(X)\n",
    "    if num_features != 2:\n",
    "        raise ValueError(f\"n_features must be equal to 2. Got {num_features} instead.\")\n",
    "\n",
    "    x0, x1 = _safe_indexing(X, 0, axis=1), _safe_indexing(X, 1, axis=1)\n",
    "\n",
    "    x0_min, x0_max = x0.min() - eps, x0.max() + eps\n",
    "    x1_min, x1_max = x1.min() - eps, x1.max() + eps\n",
    "\n",
    "    xx0, xx1 = np.meshgrid(\n",
    "        np.linspace(x0_min, x0_max, grid_resolution),\n",
    "        np.linspace(x1_min, x1_max, grid_resolution),\n",
    "    )\n",
    "\n",
    "    if hasattr(X, \"iloc\"):\n",
    "        # we need to preserve the feature names and therefore get an empty dataframe\n",
    "        X_grid = X.iloc[[], :].copy()\n",
    "        X_grid.iloc[:, 0] = xx0.ravel()\n",
    "        X_grid.iloc[:, 1] = xx1.ravel()\n",
    "    else:\n",
    "        X_grid = np.c_[xx0.ravel(), xx1.ravel()]\n",
    "\n",
    "    pred_func = _check_boundary_response_method(estimator, response_method)\n",
    "    response = pred_func(X_grid)\n",
    "\n",
    "    # convert classes predictions into integers\n",
    "    if pred_func.__name__ == \"predict\" and hasattr(estimator, \"classes_\"):\n",
    "        encoder = LabelEncoder()\n",
    "        encoder.classes_ = estimator.classes_\n",
    "        response = encoder.transform(response)\n",
    "\n",
    "    if response.ndim != 1:\n",
    "        if is_regressor(estimator):\n",
    "            raise ValueError(\"Multi-output regressors are not supported\")\n",
    "\n",
    "        # TODO: Support pos_label\n",
    "        response = response[:, 1]\n",
    "\n",
    "    if xlabel is None:\n",
    "        xlabel = X.columns[0] if hasattr(X, \"columns\") else \"\"\n",
    "\n",
    "    if ylabel is None:\n",
    "        ylabel = X.columns[1] if hasattr(X, \"columns\") else \"\"\n",
    "\n",
    "    if plot_method not in (\"contourf\", \"contour\", \"pcolormesh\"):\n",
    "        raise ValueError(\"plot_method must be 'contourf', 'contour', or 'pcolormesh'\")\n",
    "\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots()\n",
    "\n",
    "    plot_func = getattr(ax, plot_method)\n",
    "\n",
    "    surface_ = plot_func(xx0, xx1, response.reshape(xx0.shape), **kwargs)\n",
    "\n",
    "    if xlabel is not None or not ax.get_xlabel():\n",
    "        xlabel = xlabel if xlabel is None else xlabel\n",
    "        ax.set_xlabel(xlabel)\n",
    "\n",
    "    if ylabel is not None or not ax.get_ylabel():\n",
    "        ylabel = ylabel if ylabel is None else ylabel\n",
    "        ax.set_ylabel(ylabel)\n",
    "\n",
    "    return ax\n",
    "\n",
    "cmap_light = ListedColormap([\"lightblue\", \"peachpuff\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_boundary(knn, data_subset[covs_subset], cmap=cmap_light, grid_resolution=500)\n",
    "sns.scatterplot(data_subset, x='meanAnnualTemp', y='seasonalityPrecip', hue='species', s=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$k$-Nearest Neighbour can be very powerful, but it suffers from some problems.\n",
    "\n",
    "🖌️ Can you name them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Answer:_\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Decision Tree\n",
    "\n",
    "Let's add a third species into the mix to make this one more interesting: the Eastern mole\n",
    "(_Scalopus aquaticus_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_subset = ['Ammospermophilus_leucurus', 'Rangifer_tarandus', 'Scalopus_aquaticus']\n",
    "covs_subset = ['meanAnnualTemp', 'seasonalityPrecip']\n",
    "\n",
    "data_subset = data[covs_subset + ['lat', 'lon', 'species']]\n",
    "data_subset = data_subset[data_subset['species'].isin(species_subset)]\n",
    "\n",
    "X_subset = data_subset[covs_subset]\n",
    "y_subset = data_subset['species']\n",
    "\n",
    "plot_feature_space(data_subset, covs_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that looks a bit harder!\n",
    "\n",
    "We could theoretically use $k$-Nearest Neighbour just as we did before with only two species.\n",
    "However, let us instead look at another idea: the **decision tree**.\n",
    "\n",
    "Here, we recursively split the feature space along one of its dimensions to _partition_ it. For\n",
    "example, we can easily separate _Rangifer tarandus_ from the other two based on temperature, and\n",
    "(somewhat) separate the other two based on precipitation, if we apply the splits correctly. Let's\n",
    "try it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_temp = 2790\n",
    "split_precip = 580\n",
    "\n",
    "\n",
    "plot_feature_space(data_subset, covs_subset)\n",
    "ax = plt.gca()\n",
    "\n",
    "xlim, ylim = ax.get_xlim(), ax.get_ylim()\n",
    "\n",
    "ax.axvline(split_temp, color='gray', linewidth=3, alpha=0.5)\n",
    "ax.axhline(split_precip,\n",
    "           color='gray',\n",
    "           linewidth=3,\n",
    "           alpha=0.5,\n",
    "           xmin=(split_temp-xlim[0])/(xlim[1]-xlim[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's not perfect, but we could use that as a start to assign split regions to species.\n",
    "\n",
    "Above, we have defined the splits manually – in a sense, it's a mechanistic model. However, since we\n",
    "have observations, we can also create them algorithmically.\n",
    "\n",
    "🖌️ Scikit-learn has a decision tree classifier built-in. Look it up and implement it below on our\n",
    "subset data (`X_subset` and `y_subset`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision trees are easily interpretable as it is possible to understand the reason behind a model prediction.\n",
    "\n",
    "You can visualise the whole decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "\n",
    "# create a new figure\n",
    "_, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# visualize the trained decision trees\n",
    "plot_tree(\n",
    "    decision_tree,\n",
    "    feature_names=covs_subset,\n",
    "    class_names=decision_tree.classes_,\n",
    "    impurity=False,\n",
    "    label=\"root\",\n",
    "    rounded=True,\n",
    "    ax=ax\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the decision boundaries in the scatter plot, too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap_light = ListedColormap([\"lightblue\", \"peachpuff\", \"palegreen\"])\n",
    "\n",
    "\n",
    "plot_decision_boundary(decision_tree, X_subset, cmap=cmap_light)\n",
    "sns.scatterplot(data_subset, x='meanAnnualTemp', y='seasonalityPrecip', hue='species', s=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🖌️ Repeat the experiment above but increase the maximum depth beyond 2. Watch what happens. What\n",
    "can you say about the expected prediction performance of a decision tree under various depth levels?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Answer:_\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Random Forest\n",
    "\n",
    "Decision trees can be quite powerful, but as you have seen above, they can easily overfit if their\n",
    "depth is too large. This also makes them very susceptible to noise in the data, similar to\n",
    "$k$-Nearest Neighbour.\n",
    "\n",
    "Remember random forests from the lecture?\n",
    "\n",
    "🖌️ Read up about Random Forest and explain in your own words how it works and why it might\n",
    "outperform a decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Answer:_\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🖌️ Read the Scikit-learn\n",
    "[documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "about Random Forest. Create a new model and fit it to the subset training data below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the decision boundary of that model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_boundary(random_forest,\n",
    "                       X_subset,\n",
    "                       cmap=cmap_light,\n",
    "                       grid_resolution=300)\n",
    "sns.scatterplot(data_subset, x='meanAnnualTemp', y='seasonalityPrecip', hue='species', s=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now had a look at various supervised classifiers and how they behave under some data\n",
    "regimes. But how well do they actually perform? And: how can we tune them (their hyperparameters) so\n",
    "that they perform optimally? Let's take a look at these questions in the next section!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Data splitting\n",
    "\n",
    "Identifying how well our model performs has something to do with whether it makes predictions that\n",
    "are correct. The more (and more diverse) data points we evaluate this for, the more statistically\n",
    "significant our estimate becomes.\n",
    "\n",
    "However, we also cannot just reuse the data points we used to train a model to assess how well it\n",
    "performs – since the model has already seen these points, the task would be too trivial. $k$-Nearest\n",
    "Neighbour, for example, would achieve a perfect score (can you see why?).\n",
    "\n",
    "\n",
    "Instead, we have to use points for evaluation that the model has never seen before. We can do that\n",
    "by partitioning our original dataset into **splits** and using one part for training and another for\n",
    "testing.\n",
    "\n",
    "Scikit-learn offers a function to do that,\n",
    "[train_test_split](https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.train_test_split.html).\n",
    "\n",
    "🖌️ Look up the function documentation and implement it on our data subset by completing the code\n",
    "cell below.\n",
    "\n",
    "💡 As is normal, we need to indicate how much of the dataset we assign to the training and how much\n",
    "to the test set. Let us go for a split of 60% for training and 40% for testing.\n",
    "\n",
    "💡 Make sure to also provide a random integer to variable `random_state`. Look up in the\n",
    "documentation what this does (or ask the tutors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_subset_train, data_subset_test = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualise them again in feature space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = pd.concat([data_subset_train, data_subset_test])\n",
    "splits['split'] = len(data_subset_train)*['train'] + len(data_subset_test)*['test']\n",
    "\n",
    "plot_feature_space(splits, covs_subset, colour_by=['split'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And in geographic space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_mapbox(splits,\n",
    "                        lat='lat',\n",
    "                        lon='lon',\n",
    "                        title='Observations',\n",
    "                        hover_name='species',\n",
    "                        color='split',\n",
    "                        height=600,\n",
    "                        width=800,\n",
    "                        zoom=2)\n",
    "fig.update_layout(mapbox_style='open-street-map')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's also plot a histogram of how many data points we have in each split per species:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data_subset_train, y='species')\n",
    "sns.histplot(data_subset_test, y='species')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may or may not see some problems with this split.\n",
    "\n",
    "🖌️ Can you indicate scenarios where such a splitting procedure could result in problems?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Answer:_\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the lecture, you should remember that we actually need **three** splits: training, validation,\n",
    "and test.\n",
    "\n",
    "Recap as to why this is the case:\n",
    "The training-evaluation phase of an ML model pipeline consists in a loop:\n",
    "1. Choose and configure a model (set its _hyperparameters_, by hand).\n",
    "2. Train the model (fit; set model's learnable parameters) - this is done with the _training\n",
    "   set_.\n",
    "3. Measure the model's prediction performance, both on the _training and validation sets_.\n",
    "4. Assess performance: if satisfactory, move on to step 5. If not, repeat from step 1 by adjusting\n",
    "   hyperparameters. To do so, check whether the model is _underfitting_ (low accuracy on both sets)\n",
    "   or _overfitting_ (high training, low validation set performance).\n",
    "5. With the final model (no more changes to hyperparameters), predict on the _test set_ to measure\n",
    "   ultimate performance of the whole pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could use crossvalidation to create and test validation sets, but our dataset is big enough that\n",
    "we can also just define a separate validation set.\n",
    "\n",
    "🖌️ Apply the `train_test_split` function from above once more on the training set to further split\n",
    "it into 80% training and 20% validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_subset_train, data_subset_val = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can train a model on the training set and predict species labels on the validation set.\n",
    "\n",
    "🖌️ Train a random forest on the training set and predict labels on the validation set below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_val = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Accuracy Metrics\n",
    "\n",
    "Now that we have models and data splits, all we need is a measure of how good a prediction is. We can do so with accuracy metrics.\n",
    "\n",
    "For classification, the simplest is overall accuracy: the percentage of correctly predicted divided\n",
    "by the total number of data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = y_hat_val == data_subset_val['species']\n",
    "\n",
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_accuracy = correct.sum() / len(correct)\n",
    "\n",
    "print(f'Overall accuracy: {overall_accuracy:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn also has an overall accuracy calculation method built-in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "overall_accuracy_sklearn = metrics.accuracy_score(data_subset_val['species'], y_hat_val)\n",
    "\n",
    "print(f'Overall accuracy (scikit-learn): {overall_accuracy_sklearn:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall accuracy is good for a quick overview, but it can be severely misleading, especially if\n",
    "there is class imbalance or if the data exhibits other biases.\n",
    "\n",
    "Scikit-learn offers a number of other validation metrics: see [here](https://scikit-learn.org/1.5/modules/model_evaluation.html#classification-metrics).\n",
    "\n",
    "For the rest of this exercise, we'll continue with overall accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 Grid search\n",
    "\n",
    "From the parts above you are probably guessing that different ML models yield different performance\n",
    "scores. Moreover, each model can be configured with different hyperparameters; maybe there is an\n",
    "optimal combination of those? Wouldn't it make sense if we could try a few hyperparameter\n",
    "combinations from the start?\n",
    "\n",
    "Doing this is called **grid search**: we test all combinations of hyperparameter values on a grid\n",
    "and note down the accuracy the model yields for each. The best one is the model we'll retain.\n",
    "\n",
    "In the following, we will try this idea using a random forest and two of its hyperparameters:\n",
    "* Number of decision trees\n",
    "* Maximum tree depth\n",
    "\n",
    "First, let's define a few values that make sense for both of these parameters.\n",
    "\n",
    "🖌️ Add a few values (_e.g._, 5-6 for each hyperparameter) into the lists below that you think make\n",
    "sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TREES = [...]\n",
    "MAX_DEPTH = [...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's implement our grid search. Basically:\n",
    "```\n",
    "for n_tree in NUM_TREES:\n",
    "    for max_depth in MAX_DEPTH:\n",
    "        1. train model on training set\n",
    "        2. predict labels for training set, calculate accuracy\n",
    "        3. predict labels for validation set, calculate accuracy\n",
    "Choose optimal combination\n",
    "```\n",
    "\n",
    "🖌️ Implement this routine by completing the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "# arrays to store obtained training and validation accuracies\n",
    "scores_train = np.zeros((len(NUM_TREES), len(MAX_DEPTH)))\n",
    "scores_val = np.copy(scores_train)\n",
    "\n",
    "# same for running time\n",
    "runtime = np.copy(scores_train)\n",
    "\n",
    "# implement grid search\n",
    "for idx_a, n_trees in enumerate(NUM_TREES):\n",
    "    for idx_b, max_depth in enumerate(MAX_DEPTH):\n",
    "\n",
    "        # start timer\n",
    "        tic = time.time()\n",
    "\n",
    "        # create and train model\n",
    "        random_forest = ...\n",
    "        \n",
    "        # predict training and validation set accuracies\n",
    "        score_train = ...\n",
    "        score_val = ...\n",
    "\n",
    "        # stop timer\n",
    "        toc = time.time() - tic\n",
    "\n",
    "        # store values\n",
    "        scores_train[idx_a,idx_b] = score_train\n",
    "        scores_val[idx_a,idx_b] = score_val\n",
    "        runtime[idx_a,idx_b] = toc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualise the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,5))\n",
    "for idx, (name, mat) in enumerate((('acc. train', scores_train),\n",
    "                                   ('acc. val', scores_val),\n",
    "                                   ('time [s]', runtime))):\n",
    "\n",
    "    plt.subplot(1,3,idx+1)\n",
    "    sns.heatmap(mat, xticklabels=NUM_TREES, yticklabels=MAX_DEPTH)\n",
    "    plt.xlabel('No. trees')\n",
    "    plt.ylabel('Max depth')\n",
    "    plt.title(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you notice a pattern? You may want to think back about the lecture and why we are doing these\n",
    "splits in the first place.\n",
    "\n",
    "🖌️ Re-run all the code cells from Section 4.5 on, but use a different value for `random_state` in\n",
    "the two `train_test_split` cells. What happens? Can you explain why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Answer:_\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🖌️ Let's pick a combination of hyperparameters you like best:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TREES_FINAL = ...\n",
    "MAX_DEPTH_FINAL = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we keep this set of hyperparameters fixed. All that we have got left to do is to train the\n",
    "model with them and see how well it scores on the test set.\n",
    "\n",
    "🖌️ Create a random forest model with your final hyperparameters below, fit it on the training data\n",
    "and predict on the _test_ data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_test = ...\n",
    "\n",
    "print(f'Final model performance on test set: {accuracy_test:.2%}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.8 The Curse of Dimensionality\n",
    "\n",
    "From everything you have seen above, it makes sense that our features must show some correlation\n",
    "with our modelling target, for an ML model to be able to do its job.\n",
    "\n",
    "Actually, if the features have nothing to do with our target, they can even be _harmful_ for the\n",
    "model's learning process, because they can give erroneous signals.\n",
    "\n",
    "Also related to this is the fact that we can't just keep on adding more and more features, no matter\n",
    "how meaningful they are, unless we also increase the number of training points. This phenomenon is\n",
    "known as the **curse of dimensionality**.\n",
    "\n",
    "Let us see it in action. Below, we take the same random data subset from above, but add increasing\n",
    "numbers of _random_ extra features. Watch what happens with accuracy scores.\n",
    "\n",
    "\n",
    "🖌️ Complete the code cell below by specifying a supervised ML model of your choice to try this out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "\n",
    "NUM_RANDOM_FEATURES = [0, 1, 2, 5, 10, 20, 50]\n",
    "\n",
    "scores_train, scores_val = [], []\n",
    "\n",
    "for num_random in NUM_RANDOM_FEATURES:\n",
    "    data_subset_train = data_subset_train.copy()\n",
    "    data_subset_val = data_subset_val.copy()\n",
    "    covs_subset_copy = copy.deepcopy(covs_subset)\n",
    "\n",
    "    # generate random features and append to data frame\n",
    "    for idx in range(num_random):\n",
    "        feat_name = f'random_{idx}'\n",
    "        covs_subset_copy.append(feat_name)\n",
    "        data_subset_train[feat_name] = np.random.randn(len(data_subset_train))\n",
    "        data_subset_val[feat_name] = np.random.randn(len(data_subset_val))\n",
    "    \n",
    "    # fit model on data_subset_train and calculate overall accuracy (OA) obtained on data_subset_val\n",
    "    oa_train = ...\n",
    "    oa_val = ...\n",
    "\n",
    "    scores_train.append(oa_train)\n",
    "    scores_val.append(oa_val)\n",
    "\n",
    "\n",
    "# plot scores\n",
    "plt.plot(NUM_RANDOM_FEATURES, scores_train, 'b-', label='train')\n",
    "plt.plot(NUM_RANDOM_FEATURES, scores_val, 'r-', label='val')\n",
    "plt.legend()\n",
    "plt.xlabel('Number of random features')\n",
    "plt.ylabel('Accuracy score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the complexity (learning capacity) of your model, you should be able to see some of the\n",
    "following phenomena:\n",
    "* Increasing training set score, decreasing validation set score\n",
    "* Stabilising training set score, decreasing validation set score\n",
    "* Both going down\n",
    "\n",
    "Whatever you do, the validation set score will likely go down: the model overfits to the noisy\n",
    "features!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bonus: counteract the curse of dimensionality**\n",
    "\n",
    "As explained, the curse of dimensionality can also happen if we add meaningful features but have too\n",
    "many of them. What can we do in this case?\n",
    "\n",
    "🖌️ In the code cell below, apply a PCA with a sensible number of principal components to the\n",
    "features prior to training a model on it. Identify the number of features with a scree plot (see\n",
    "above). Add your model again to the code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's fix the number of random features for now\n",
    "NUM_RANDOM_FEATURES = 50\n",
    "\n",
    "# generate random features and append to data frame\n",
    "data_subset_train = data_subset_train.copy()\n",
    "data_subset_val = data_subset_val.copy()\n",
    "covs_subset_copy = copy.deepcopy(covs_subset)\n",
    "\n",
    "for idx in range(num_random):\n",
    "    feat_name = f'random_{idx}'\n",
    "    covs_subset_copy.append(feat_name)\n",
    "    data_subset_train[feat_name] = np.random.randn(len(data_subset_train))\n",
    "    data_subset_val[feat_name] = np.random.randn(len(data_subset_val))\n",
    "\n",
    "\n",
    "# apply PCA on training set first\n",
    "pc_train = ...\n",
    "\n",
    "# fit model on principal components\n",
    "model = ...\n",
    "\n",
    "# predict and calculate accuracy scores\n",
    "oa_train = ...\n",
    "oa_val = ...\n",
    "\n",
    "print(f'Final score with {NUM_RANDOM_FEATURES} random features + PCA: train: {oa_train:.2%}, val: {oa_val:.2%}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Exercise: putting it all together\n",
    "\n",
    "We've now seen a \"complete\" ML pipeline:\n",
    "1. Data loading\n",
    "2. Data cleaning (in this case, we only had to remove NaN values)\n",
    "3. Exploration and visualisation (scatter plots, histograms; clustering, dimensionality reduction)\n",
    "4. Data splitting (training, validation, and test sets)\n",
    "5. Model selection: grid search of hyperparameters using training and validation sets\n",
    "6. Model prediction on test set\n",
    "\n",
    "We could now go ahead and start to interpret these results, maybe look for patterns, _etc._\n",
    "That step is called _inference_, and we will see a bit of that towards the end of the module.\n",
    "\n",
    "Before that, however, let's see how well our model works on _all_ the data! Remember that we've only\n",
    "used a subset of three species and two covariates above.\n",
    "\n",
    "🖌️ Train a supervised species prediction model for the full dataset, starting from the `data`\n",
    "DataFrame. You can choose _(a.)_ which [scikit-learn ML\n",
    "model](https://scikit-learn.org/1.6/supervised_learning.html) you want to use and _(b.)_ which two\n",
    "hyperparameters you want to apply grid search for. Ultimately, you should end up with a\n",
    "`final_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't forget to apply the splitting\n",
    "data_train, data_val, data_test = ...\n",
    "\n",
    "final_model = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how well your model performs on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test set\n",
    "y_hat_test = final_model.predict(data_test[cov_cols])\n",
    "\n",
    "# calculate accuracy\n",
    "accuracy_test = metrics.accuracy_score(data_test['species'], y_hat_test)\n",
    "\n",
    "print(f'Final model performance on entire test set: {accuracy_test:.2%}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are you happy with your result?\n",
    "\n",
    "If you are surprised that the performance is now a lot worse, let's remind ourselves why overall\n",
    "accuracy is a flawed metric.\n",
    "\n",
    "In more detail, let's calculate accuracy scores for each species separately, and plot them against\n",
    "the number of training points accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_scores = {}\n",
    "\n",
    "for species in data_train['species'].unique():\n",
    "    valid = data_test['species'] == species\n",
    "    score = metrics.accuracy_score(data_test['species'][valid], y_hat_test[valid])\n",
    "    accuracy_scores[species] = score\n",
    "\n",
    "sns.barplot(accuracy_scores)\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might find that your model performs really well for some, but really poorly for other species.\n",
    "\n",
    "If you go back to the scatter plots of covariate values, as well as the unsupervised learning\n",
    "outputs we have taken a look at ($k$-means, t-SNE, UMAP), you might find the answer why some species\n",
    "are predicted better than others.\n",
    "\n",
    "🖌️ What could have influenced prediction accuracy? Write down a few hypotheses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Answer:_\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Regression\n",
    "\n",
    "Similarly to classification, we can also do regression – that is, prediction of a variable with some\n",
    "sort of ordering.\n",
    "\n",
    "Regression really only makes sense if the scale our variable is:\n",
    "* Ordinal (although we could use some form of classification here, too): _e.g._, IUCN threat status\n",
    "* Interval: _e.g._, duration of growing season of a tree\n",
    "* Ratio: _e.g._, biomass of a tree\n",
    "\n",
    "\n",
    "Like classification, regression models belong to the family of supervised learning algorithms.\n",
    "\n",
    "Let us first create a toy dataset for a regression task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import make_regression function from scikit-learn datasets module\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "# generate a random dataset for regression with some noise and 200 points\n",
    "X_reg, y_reg = make_regression(n_features=1, noise=10, n_samples=200)\n",
    "\n",
    "# use seaborn to generate a scatterplot\n",
    "sns.scatterplot(x=X_reg.flatten(), y=y_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Linear regression\n",
    "\n",
    "A linear regression model assumes that there is a **linear** relation between the features and the\n",
    "target variable:\n",
    "\n",
    "$$ {\\bf y} = a {\\bf x} + b $$\n",
    "\n",
    "The parameters $a$ (slope) and $b$ (bias) that best \"fit\" the data points can be found\n",
    "algorithmically.\n",
    "\n",
    "How good a model fits the data is determined by minimizing some **loss** or error.\n",
    "\n",
    "In the case of the linear model, the loss is measured by the Mean Squared Error (MSE) – you have\n",
    "seen this in the lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the Linear Regression model from scikit-learn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# fit a linear model to the example data\n",
    "linear_reg_1 = LinearRegression().fit(X_reg, y_reg)\n",
    "\n",
    "# plot the datapoints. x = features, y = target value\n",
    "ax = sns.scatterplot(x=X_reg.flatten(), y=y_reg)\n",
    "\n",
    "x_min = X_reg.min()\n",
    "x_max = X_reg.max()\n",
    "\n",
    "# generate a prediction using the linear model on the example data\n",
    "pred = linear_reg_1.predict([[x_min], [x_max]])\n",
    "\n",
    "# plot the predicted line\n",
    "ax.plot([x_min, x_max], pred, color=\"black\", linestyle=\"--\", linewidth=2)\n",
    "\n",
    "# add labels to axis\n",
    "ax.set_xlabel(\"x = Features\")\n",
    "ax.set_ylabel(\"y = Target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once fitted, a prediction for points outside the dataset is computed with the same formula:\n",
    "\n",
    "$$ {\\bf y_{pred}} = a {\\bf x_{test}} + b $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a new test point at x = 2\n",
    "test_point = [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the linear model to predict its target value\n",
    "predicted_value = linear_reg_1.predict([test_point])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data points. x = features, y = target value\n",
    "ax = sns.scatterplot(x=X_reg.flatten(), y=y_reg)\n",
    "\n",
    "# plot the predicted line\n",
    "ax.plot([x_min, x_max], pred, color=\"black\", linestyle=\"--\", linewidth=2)\n",
    "\n",
    "# draw a point at the test point with its predicted value\n",
    "plt.scatter(test_point, [predicted_value], color=\"red\")\n",
    "\n",
    "y_min = pred.min()\n",
    "\n",
    "# draw a vertical arrow from the x-axis at x = test_point to its predicted value\n",
    "ax.arrow(\n",
    "    2,\n",
    "    y_min,\n",
    "    0,\n",
    "    predicted_value - y_min,\n",
    "    color=\"red\",\n",
    "    head_width=0.1,\n",
    "    head_length=10,\n",
    "    length_includes_head=True,\n",
    ")\n",
    "\n",
    "# draw a horizontal arrow from the point (x, y) = (test_point, predicted_value) to\n",
    "# the y-axis at y = predicted_value\n",
    "ax.arrow(\n",
    "    test_point[0],\n",
    "    predicted_value,\n",
    "    -test_point[0] + x_min,\n",
    "    0,\n",
    "    color=\"red\",\n",
    "    head_width=10,\n",
    "    head_length=0.1,\n",
    "    length_includes_head=True,\n",
    ")\n",
    "\n",
    "# add the linear formula to the plot\n",
    "ax.text(-1, 50, \"y = ax + b\")\n",
    "\n",
    "# add labels to axis\n",
    "ax.set_xlabel(\"x = Features\")\n",
    "ax.set_ylabel(\"y = Target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, based on what we have seen for classification, we should be able to make the same thought jumps\n",
    "regarding complexity of the data: we can try to regress a non-linear relationship, and we can even\n",
    "use similar methods to do so as for classification.\n",
    "\n",
    "💡 In the next two weeks you'll see that we can cast classification as a regression problem.\n",
    "Keyword: logistic regression. Let's save this for later. 😉"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Nearest Neighbour Regression\n",
    "\n",
    "If we can calculate distances between points to infer labels (_cf._ $k$-Nearest Neighbour\n",
    "classifier), we can also use it to infer regression targets.\n",
    "\n",
    "Let's see this in action with a more complex dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create another dataset\n",
    "# here, target_ideal is a non-linear function of x\n",
    "X_reg_2 = np.arange(0, 100, 2.0)\n",
    "y_reg_2_ideal = np.sin(X_reg_2 / 10) + (X_reg_2 / 50) ** 2\n",
    "\n",
    "# add some noise to our target variable target_ideal\n",
    "y_reg_2 = y_reg_2_ideal + np.random.normal(size=len(y_reg_2_ideal)) * 0.3\n",
    "\n",
    "\n",
    "# plot scatter points (x = features, y = target)\n",
    "ax = sns.scatterplot(x=X_reg_2, y=y_reg_2)\n",
    "\n",
    "# add title\n",
    "ax.set_title(\"Non-linear dataset\")\n",
    "\n",
    "# add labels to axis\n",
    "ax.set_xlabel(\"x = Features\")\n",
    "ax.set_ylabel(\"y = Target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with classification, linear models are very rigid and will underfit here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit linear model\n",
    "linear_reg_2 = LinearRegression()\n",
    "linear_reg_2.fit(X_reg_2.reshape(-1, 1), y_reg_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on a range of test points\n",
    "test_points = np.linspace(0, 100, 1000)\n",
    "linear_reg_pred_2 = linear_reg_2.predict(test_points.reshape(-1, 1))\n",
    "\n",
    "# plot dataset\n",
    "sns.scatterplot(x=X_reg_2, y=y_reg_2)\n",
    "\n",
    "# plot the fitted linear model\n",
    "sns.lineplot(x=test_points, y=linear_reg_pred_2, color=\"red\", label=\"linear regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what Nearest Neighbour regression does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Nearest Neighbour Regression model from scikit-learn\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# fit nearest neighbour model\n",
    "knn_reg = KNeighborsRegressor(n_neighbors=1)\n",
    "knn_reg.fit(X_reg_2.reshape(-1, 1), y_reg_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on a range of test points\n",
    "test_points = np.linspace(0, 100, 1000)\n",
    "knn_reg_pred_2 = knn_reg.predict(test_points.reshape(-1, 1))\n",
    "\n",
    "# plot dataset\n",
    "sns.scatterplot(x=X_reg_2, y=y_reg_2)\n",
    "\n",
    "# plot fitted nearest neighbour model\n",
    "sns.lineplot(x=test_points, y=knn_reg_pred_2, color=\"red\", label=\"nearest neighbour\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That works better.\n",
    "\n",
    "However, nearest neighbour regression suffers from the same problems as nearest neighbour\n",
    "classification:\n",
    "    \n",
    "* Sensitive to noise\n",
    "* Heavy on computation and memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Random Forest Regression\n",
    "\n",
    "You guessed it – Random Forest can be adapted to perform regression, too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Nearest Neighbor Regression model from scikit-learn\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "# fit random forest regression model\n",
    "rf_reg = RandomForestRegressor()\n",
    "rf_reg.fit(X_reg_2.reshape(-1, 1), y_reg_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on a range of test points\n",
    "test_points = np.linspace(0, 100, 1000)\n",
    "rf_reg_pred_2 = rf_reg.predict(test_points.reshape(-1, 1))\n",
    "\n",
    "# plot the fitted linear model and random forest\n",
    "sns.scatterplot(x=X_reg_2, y=y_reg_2)\n",
    "\n",
    "sns.lineplot(x=test_points, y=rf_reg_pred_2, color=\"red\", label=\"random forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Evaluation\n",
    "\n",
    "It should come as no surprise that _every single step_ from here on for regression works the same as\n",
    "with classification, including definition of performance metric, train/val/test splits,\n",
    "hyperparameter selection, _etc._.\n",
    "\n",
    "The key difference is the metrics, in case of regression often identical to the loss functions (more\n",
    "on that next week).\n",
    "\n",
    "The first one we can take a look at is the **Mean Absolute Error (MAE)**:\n",
    "\n",
    "$$ MAE = \\frac{1}{n} \\sum_{i = 1}^{n} |y_{true} - y_{pred}| $$\n",
    "\n",
    "Where $|...|$ denotes the absolute function (all values become positive).\n",
    "\n",
    "The absolute error can easily be visualised..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot training dataset\n",
    "ax = sns.scatterplot(x=X_reg_2, y=y_reg_2)\n",
    "\n",
    "# plot fitted line\n",
    "sns.lineplot(x=test_points, y=linear_reg_pred_2, color=\"red\", label=\"linear regression\")\n",
    "\n",
    "# use linear model to predict on original dataset\n",
    "y_reg_2_linear_pred = linear_reg_2.predict(X_reg_2.reshape(-1, 1))\n",
    "\n",
    "# plot absolute errors\n",
    "for x, y_true, y_pred in zip(X_reg_2, y_reg_2, y_reg_2_linear_pred):\n",
    "    ax.plot([x, x], [y_true, y_pred], alpha=0.5, color=\"black\", linewidth=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and calculated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the array of differences in prediction and true value\n",
    "error = y_reg_2 - y_reg_2_linear_pred\n",
    "\n",
    "# compute the absolute of each error\n",
    "absolute_error = np.abs(error)\n",
    "\n",
    "# compute the mean\n",
    "MAE = absolute_error.mean()\n",
    "\n",
    "print(f\"MAE of the linear model on the training dataset: {MAE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can calculate the **Mean Squared Error (MSE)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the square of each error\n",
    "squared_error = error ** 2\n",
    "\n",
    "# compute the mean\n",
    "MSE = squared_error.mean()\n",
    "\n",
    "print(f\"MSE of the linear model on the training dataset: {MSE}\")\n",
    "\n",
    "# with scikit-learn\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# use scikit-learn function to compute MSE\n",
    "MSE = mean_squared_error(y_true=y_reg_2, y_pred=y_reg_2_linear_pred)\n",
    "\n",
    "print(f\"MSE of the linear model on the training dataset (with Scikit-learn): {MSE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Here](https://scikit-learn.org/1.5/api/sklearn.metrics.html#regression-metrics) are all the\n",
    "implementations of Scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's again split the dataset to compare regression models accordingly. We'll only use two splits\n",
    "for demonstration purposes; as said, all the grid search part would remain the same if implemented\n",
    "properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split features and target into train and test. Test is 30% of all data.\n",
    "X_reg_2_train, X_reg_2_test, y_reg_2_train, y_reg_2_test = train_test_split(\n",
    "    X_reg_2, y_reg_2, test_size=0.3\n",
    ")\n",
    "\n",
    "# iterate over model types\n",
    "for model in [\n",
    "    LinearRegression(),\n",
    "    KNeighborsRegressor(n_neighbors=1),\n",
    "    RandomForestRegressor(),\n",
    "]:\n",
    "    # fit the model to training data\n",
    "    model.fit(X_reg_2_train.reshape(-1, 1), y_reg_2_train)\n",
    "\n",
    "    # use fitted model to predict in test data\n",
    "    y_pred = model.predict(X_reg_2_test.reshape(-1, 1))\n",
    "\n",
    "    # compute MSE using the predictions and ground truth\n",
    "    mse = mean_squared_error(y_true=y_reg_2_test, y_pred=y_pred)\n",
    "\n",
    "    print(f\"{str(model):>34} mse = {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot train and test points\n",
    "sns.scatterplot(\n",
    "    x=X_reg_2_train,\n",
    "    y=y_reg_2_train,\n",
    "    color=\"black\",\n",
    "    marker=\"o\",\n",
    "    label=\"train\",\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=X_reg_2_test,\n",
    "    y=y_reg_2_test,\n",
    "    color=\"black\",\n",
    "    marker=\"x\",\n",
    "    label=\"test\",\n",
    ")\n",
    "\n",
    "# iterate over model types\n",
    "for model in [\n",
    "    LinearRegression(),\n",
    "    KNeighborsRegressor(n_neighbors=1),\n",
    "    RandomForestRegressor(),\n",
    "]:\n",
    "    # fit the model to training data\n",
    "    model.fit(X_reg_2_train.reshape(-1, 1), y_reg_2_train)\n",
    "\n",
    "    # generate predictions in range of data points\n",
    "    test_points = np.linspace(0, 100, 1000)\n",
    "    y_pred = model.predict(test_points.reshape(-1, 1))\n",
    "\n",
    "    # plot predicted line\n",
    "    sns.lineplot(x=test_points, y=y_pred, label=str(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And again, just like for classification, we can have more than one feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a synthetic dataset for regression with 2 features\n",
    "X_2D, y_2D = make_regression(\n",
    "    n_samples=200,\n",
    "    n_features=2,\n",
    "    n_targets=1,\n",
    ")\n",
    "\n",
    "# visualise with seaborn\n",
    "# plot points at (x = feature 1, y = feature 2)\n",
    "# use the target variable to determine point size and colour\n",
    "grid = sns.relplot(\n",
    "    x=X_2D[:, 0],\n",
    "    y=X_2D[:, 1],\n",
    "    size=y_2D,\n",
    "    sizes=(40, 400),\n",
    "    alpha=0.5,\n",
    "    hue=y_2D,\n",
    ")\n",
    "\n",
    "# add axis labels\n",
    "grid.ax.set_xlabel(\"feature 1\")\n",
    "grid.ax.set_ylabel(\"feature 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into train and test\n",
    "X_2D_train, X_2D_test, y_2D_train, y_2D_test = train_test_split(\n",
    "    X_2D,\n",
    "    y_2D,\n",
    "    test_size=0.3,\n",
    ")\n",
    "\n",
    "# fit a Nearest Neighbor Regression model to training data\n",
    "knn_reg_2D = KNeighborsRegressor(n_neighbors=1).fit(X_2D_train, y_2D_train)\n",
    "\n",
    "# create a mesh of points\n",
    "XX, YY = np.meshgrid(np.linspace(-4, 4, 100), np.linspace(-4, 4, 100))\n",
    "\n",
    "# predict on each point in mesh\n",
    "knn_2D_predictions = knn_reg_2D.predict(np.c_[XX.flatten(), YY.flatten()])\n",
    "\n",
    "# compute the min and max value of predictions\n",
    "vmin, vmax = knn_2D_predictions.min(), knn_2D_predictions.max()\n",
    "\n",
    "# select colormap\n",
    "# see available colormaps at https://matplotlib.org/stable/tutorials/colors/colormaps.html\n",
    "cmap = \"plasma\"\n",
    "\n",
    "# plot\n",
    "ax = plt.pcolormesh(\n",
    "    XX,\n",
    "    YY,\n",
    "    knn_2D_predictions.reshape(XX.shape),\n",
    "    vmin=vmin,\n",
    "    vmax=vmax,\n",
    "    cmap=cmap,\n",
    ")\n",
    "\n",
    "# create a color bar to indicate mapping between columns and target values\n",
    "cbar = plt.colorbar()\n",
    "\n",
    "# add label to color bar\n",
    "cbar.set_label(\"target\")\n",
    "\n",
    "# plot training data as small round points\n",
    "plt.scatter(\n",
    "    X_2D_train[:, 0],\n",
    "    X_2D_train[:, 1],\n",
    "    c=y_2D_train,\n",
    "    s=20,\n",
    "    edgecolor=\"black\",\n",
    "    label=\"train\",\n",
    "    vmin=vmin,\n",
    "    vmax=vmax,\n",
    "    cmap=cmap,\n",
    ")\n",
    "\n",
    "# compute predictions at test points\n",
    "y_2D_test_pred = knn_reg_2D.predict(X_2D_test)\n",
    "\n",
    "# compute prediction absolute error\n",
    "error = np.abs(y_2D_test - y_2D_test_pred)\n",
    "\n",
    "# plot test data as large square markers\n",
    "# color squares using true value of target variable\n",
    "# use absolute error to determine square size\n",
    "plt.scatter(\n",
    "    X_2D_test[:, 0],\n",
    "    X_2D_test[:, 1],\n",
    "    s=error,\n",
    "    c=y_2D_test,\n",
    "    marker=\"s\",\n",
    "    edgecolor=\"black\",\n",
    "    label=\"test\",\n",
    "    vmin=vmin,\n",
    "    vmax=vmax,\n",
    "    cmap=cmap,\n",
    "    sizes=(20, 100),\n",
    ")\n",
    "\n",
    "# add legend to figure\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusion\n",
    "\n",
    "Congratulations for making it to the end of today's exercise! You have seen many different concepts,\n",
    "but together, they gave you insights into the basics of machine learning. No matter the size of the\n",
    "problem, from a few samples you took in a field course to training large deep learning models, many\n",
    "of these concepts are represented in there.\n",
    "\n",
    "A few final comments on the practical side of things:\n",
    "\n",
    "\n",
    "### Which algorithm works best?\n",
    "\n",
    "Short answer: it depends!\n",
    "\n",
    "> The “No Free Lunch” Theorem argues that, without having substantive information about the\n",
    "> modelling problem, there is no single model that will always do better than any other model.\n",
    "> Because of this, a strong case can be made to try a wide variety of techniques, then determine\n",
    "> which model to focus on.\n",
    ">\n",
    "> — Pages 25-26, Applied Predictive Modeling, 2013.\n",
    "\n",
    "\n",
    "There is no silver bullet. However, a good recommendation is to **start simple**. For example,\n",
    "random forest is very easy to implement (as you have seen) and quick to train; often, it already\n",
    "gives good performance, too. Also, explore your data beforehand, via visualisation, clustering,\n",
    "dimensionality reduction, _etc._ – just as we've done above.\n",
    "\n",
    "This will give you an idea of how separable your data is. The next step is to try different\n",
    "features, and perhaps even collect more training data.\n",
    "\n",
    "\n",
    "### How much data do I need?\n",
    "\n",
    "Short answer: it depends!\n",
    "\n",
    "The number of required training points roughly scales with the following factors:\n",
    "1. Separability of data\n",
    "2. Complexity of your ML model (its learning capacity)\n",
    "3. Balance across label classes\n",
    "4. Diversity of features (this goes hand-in-hand with point 1)\n",
    "\n",
    "In some sense, it depends also on how accurate your model should be. There might be situations where\n",
    "you can sacrifice a bit of performance in favour of _e.g._ runtime. A more complex model (and more\n",
    "data) requires more compute cycles. If you want to deploy a model on a low-power device, such as a\n",
    "drone or camera trap, you might not be able to opt for the biggest model! Instead, you may get away\n",
    "with one that sacrifices _e.g._ 5% accuracy score but is a lot more lightweight to train.\n",
    "\n",
    "\n",
    "Some problems, however, may need thousands, tens of thousands, perhaps billions of data points\n",
    "(ChatGPT?). Also, their features may be so complicated that a conventional ML model just doesn't cut\n",
    "it anymore – such as images. For these, we need something more powerful. Stay tuned for the next two\n",
    "weeks! 🤠"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aide",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
