{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66069f57-31fd-4631-a83b-5db6eb731b8a",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57257414-892d-4a96-bde8-1b556e61d337",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import model_selection\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7c2888-a904-486c-a693-4899f4a3f3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _check_boundary_response_method(estimator):\n",
    "    has_classes = hasattr(estimator, \"classes_\")\n",
    "\n",
    "    if has_classes and len(estimator.classes_) > 2:\n",
    "        methods_list = [\"predict\"]\n",
    "    else:\n",
    "        methods_list = [\"decision_function\", \"predict_proba\", \"predict\"]\n",
    "\n",
    "    prediction_method = [getattr(estimator, method, None) for method in methods_list]\n",
    "\n",
    "    prediction_method = reduce(lambda x, y: x or y, prediction_method)\n",
    "\n",
    "    if prediction_method is None:\n",
    "        raise ValueError(\n",
    "            f\"{estimator.__class__.__name__} has none of the following attributes: \"\n",
    "            f\"{', '.join(methods_list)}.\"\n",
    "        )\n",
    "\n",
    "    return prediction_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaa4d8c-b90a-4db9-9839-529be9445d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(\n",
    "    estimator,\n",
    "    x,\n",
    "    y,\n",
    "    *,\n",
    "    plot_method=\"contourf\",\n",
    "    grid_resolution=100,\n",
    "    eps=1.0,\n",
    "    ax=None,\n",
    "    **kwargs,\n",
    "):\n",
    "    x_min, x_max = x.min() - eps, x.max() + eps\n",
    "    y_min, y_max = y.min() - eps, y.max() + eps\n",
    "    xx, yy = np.meshgrid(\n",
    "        np.linspace(x_min, x_max, grid_resolution),\n",
    "        np.linspace(y_min, y_max, grid_resolution),\n",
    "    )\n",
    "    X_grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "    pred_func = _check_boundary_response_method(estimator)\n",
    "    response = pred_func(X_grid)\n",
    "\n",
    "    # convert classes predictions into integers\n",
    "    if pred_func.__name__ == \"predict\" and hasattr(estimator, \"classes_\"):\n",
    "        encoder = LabelEncoder()\n",
    "        encoder.classes_ = estimator.classes_\n",
    "        response = encoder.transform(response)\n",
    "\n",
    "    if response.ndim != 1:\n",
    "        response = response[:, 1]\n",
    "\n",
    "    response = response.reshape(xx.shape)\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots()\n",
    "    surface = getattr(ax, plot_method)(xx, yy, response, **kwargs)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d587887a-c6aa-4e45-a16d-faceabcea094",
   "metadata": {},
   "source": [
    "## Example application - Species identification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a30df8-5224-4e8f-b2ef-3cecefe899f2",
   "metadata": {},
   "source": [
    "Given some features derived from an image, audio recording, a dna sample, or some physical measurements can we identify the species from which the data came?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbf2c4e-b5ca-4fc8-9a90-fa7d51904bbf",
   "metadata": {},
   "source": [
    "![plant classification through leaf images](https://miro.medium.com/max/720/1*leLKD1K6sMtuqr9KK8RaJg.webp)\n",
    "\n",
    "(image from [Building a Convolutional Neural Network to Classify Birds](https://blog.jovian.ai/building-a-convolutional-neural-network-to-classify-birds-528794240fa1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8819f70-a9ab-4390-9072-e369f6021309",
   "metadata": {},
   "source": [
    "Given our feature vector <b style=\"color: deepskyblue\">x</b>, can we predict the correct species (i.e. class label) <span style=\"color: coral;\">y</span>?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0db5fed-1f83-4b56-9539-b91efb6285e2",
   "metadata": {},
   "source": [
    "Given this digital image, can we predict which species is depicted?\n",
    "\n",
    "![input image](https://miro.medium.com/max/514/1*60KGh4n-Rt3sjcWJVgRmlA.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab491ff-29c7-4503-8fc9-f3e47406ee17",
   "metadata": {},
   "source": [
    "## Supervised classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7931de-7fdb-495c-8302-0037fddc8473",
   "metadata": {},
   "source": [
    "There exists a whole host of different classification algorithms each with their own strengths and weaknesses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1922679e-8315-4ffa-98de-a096ca13a4bb",
   "metadata": {},
   "source": [
    "Popular Algorithms:\n",
    "* Nearest Neighbour\n",
    "* Logistic Regression\n",
    "* Support Vector Machines (SVM)\n",
    "* Decision Trees\n",
    "* Random Forests\n",
    "* Neural Networks\n",
    "* Gaussian Process Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979c5de9-d32b-41ea-8b4f-0bdd931408a0",
   "metadata": {},
   "source": [
    "For example, the nearest neighbour algorithm is flexible but requires a lot of computation.\n",
    "\n",
    "What are some alternatives? Is there a way that involves less computation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e97069-6e12-4e6b-9a7f-dbc59fb3a21f",
   "metadata": {},
   "source": [
    "### Example: Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0917695-23f9-4788-9043-4ff98f59f7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a the Iris dataset from scikit-learn.\n",
    "data = load_iris(as_frame=True)\n",
    "iris = data.data\n",
    "iris[\"species\"] = [data.target_names[i] for i in data.target]\n",
    "\n",
    "# Only use petal length and width attributes.\n",
    "x = \"petal length (cm)\"\n",
    "y = \"petal width (cm)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a0f4fb-1db2-40be-bdca-b40e8604bf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the full dataset, color indicates the species\n",
    "sns.scatterplot(data=iris, x=x, y=y, hue=\"species\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26867c7-c82a-486b-b510-569a04216f09",
   "metadata": {},
   "source": [
    "## Linear classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f71c27-1d7b-406b-a685-4b2dabe9f02d",
   "metadata": {},
   "source": [
    "### Separable data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8db599d-3f31-4598-9c08-f7e317c8d736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only data of the setosa and virginica species\n",
    "separable_dataset = iris[iris.species.isin([\"setosa\", \"versicolor\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086c42e7-2a9b-4b8e-8a4b-fa1413ed0db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data points\n",
    "sns.scatterplot(\n",
    "    data=separable_dataset,\n",
    "    x=\"petal length (cm)\",\n",
    "    y=\"petal width (cm)\",\n",
    "    hue=\"species\",\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd61fee9-7b40-421b-afa3-46875bb9839e",
   "metadata": {},
   "source": [
    "Data points from the different species are clearly separated. In fact, they can be separated by a line, and new points can be classified depending\n",
    "on which side of the line they fall.\n",
    "\n",
    "This is what a linear classifier does, in essence. Here we will use the linear support vector classifier (SVC). See [here](https://scikit-learn.org/stable/modules/svm.html#svc) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e50586-7d07-4f7b-a1de-912f6bf8ec1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a linear support vector classifier (SVC) on the separable dataset\n",
    "clf = LinearSVC().fit(\n",
    "    separable_dataset[[x, y]].values,\n",
    "    separable_dataset[\"species\"],\n",
    ")\n",
    "\n",
    "# Plot the decision boundary of the linear classifier\n",
    "ax = plot_decision_boundary(\n",
    "    clf,\n",
    "    x=separable_dataset[x],\n",
    "    y=separable_dataset[y],\n",
    "    grid_resolution=100,\n",
    "    plot_method=\"contour\",\n",
    "    levels=[0],\n",
    ")\n",
    "\n",
    "# Plot the decision regions of the linear classifier\n",
    "plot_decision_boundary(\n",
    "    clf,\n",
    "    x=separable_dataset[x],\n",
    "    y=separable_dataset[y],\n",
    "    grid_resolution=100,\n",
    "    levels=[-100, 0, 100],\n",
    "    ax=ax,\n",
    "    cmap=ListedColormap([\"cornflowerblue\", \"cyan\", \"orange\"]),\n",
    ")\n",
    "\n",
    "# Overlay the dataset points\n",
    "sns.scatterplot(\n",
    "    data=separable_dataset,\n",
    "    x=x,\n",
    "    y=y,\n",
    "    hue=\"species\",\n",
    "    ax=ax,\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac5ef56-e06b-4584-aa87-6b51a07d0eb0",
   "metadata": {},
   "source": [
    "Evaluating this model is computationally cheap and fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68487acc-f52f-412e-b2a2-c9a89c8055bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_point = np.random.uniform(low=[0, 0], high=[6, 2.5], size=2).reshape(-1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bce1dc-c9cd-41d8-87ad-5a3e113c2e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit clf.decision_function(random_point)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a41cdf-0872-49da-82e1-af226b470b84",
   "metadata": {},
   "source": [
    "Compared to the nearest neighbour classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba23d93-1216-46ae-b9a1-d69ccdf1a8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = KNeighborsClassifier(n_neighbors=1).fit(\n",
    "    separable_dataset[[x, y]].values,\n",
    "    separable_dataset[\"species\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7078492-c7df-4cfd-8d98-4f37a8016c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit nn_model.predict(random_point)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d24a37a-dc00-41e6-9768-d4dc2908bf86",
   "metadata": {},
   "source": [
    "it is around 10 times faster, and does not get slower for larger datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b532d5e4-3ab1-4d62-bec2-55436e30924d",
   "metadata": {},
   "source": [
    "### Non-separable data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e317d43-41df-4639-9c0c-5935363aaa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only data of the versicolor and virginica species\n",
    "non_separable_species = [\"virginica\", \"versicolor\"]\n",
    "non_separable_dataset = iris[iris.species.isin(non_separable_species)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b424c6b6-667f-4d61-80e0-1ad428d8f5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data points\n",
    "x = \"petal length (cm)\"\n",
    "y = \"petal width (cm)\"\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=non_separable_dataset,\n",
    "    x=x,\n",
    "    y=y,\n",
    "    hue=\"species\",\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82561fb1-2c2c-4175-b8d5-c97a66cec2fa",
   "metadata": {},
   "source": [
    "Points of different species are not as separated as before. There is no line that will cleanly cut into the two species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fff99c-8e57-408e-96c9-e6209ab6e1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a linear support vector machine on the non-linearly-separable dataset\n",
    "clf = LinearSVC().fit(\n",
    "    non_separable_dataset[[x, y]].values,\n",
    "    non_separable_dataset[\"species\"],\n",
    ")\n",
    "\n",
    "# Plot the decision boundary of the linear classifier\n",
    "ax = plot_decision_boundary(\n",
    "    clf,\n",
    "    x=non_separable_dataset[x],\n",
    "    y=non_separable_dataset[y],\n",
    "    grid_resolution=100,\n",
    "    plot_method=\"contour\",\n",
    "    levels=[0],\n",
    ")\n",
    "\n",
    "plot_decision_boundary(\n",
    "    clf,\n",
    "    x=non_separable_dataset[x],\n",
    "    y=non_separable_dataset[y],\n",
    "    grid_resolution=100,\n",
    "    levels=[-100, 0, 100],\n",
    "    ax=ax,\n",
    "    cmap=ListedColormap([\"cornflowerblue\", \"cyan\", \"orange\"]),\n",
    ")\n",
    "\n",
    "# Overlay the dataset points\n",
    "sns.scatterplot(\n",
    "    data=non_separable_dataset,\n",
    "    x=x,\n",
    "    y=y,\n",
    "    hue=\"species\",\n",
    "    ax=ax,\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea35644f-2999-435a-a886-a23cd0483e4c",
   "metadata": {},
   "source": [
    "## Non linear classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd796bd0-24ac-4b55-9475-a4e15d1c6751",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ff42b8-a9c4-4a30-84bd-031f3bbf175e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a non-linear support vector machine on the non-linearly-separable dataset\n",
    "clf = SVC(C=100, gamma=10).fit(\n",
    "    non_separable_dataset[[x, y]].values,\n",
    "    non_separable_dataset[\"species\"],\n",
    ")\n",
    "\n",
    "# Plot the decision boundary of the linear classifier\n",
    "ax = plot_decision_boundary(\n",
    "    clf,\n",
    "    x=non_separable_dataset[x],\n",
    "    y=non_separable_dataset[y],\n",
    "    grid_resolution=100,\n",
    "    plot_method=\"contour\",\n",
    "    levels=[0],\n",
    ")\n",
    "\n",
    "plot_decision_boundary(\n",
    "    clf,\n",
    "    x=non_separable_dataset[x],\n",
    "    y=non_separable_dataset[y],\n",
    "    grid_resolution=100,\n",
    "    levels=[-100, 0, 100],\n",
    "    ax=ax,\n",
    "    cmap=ListedColormap([\"cornflowerblue\", \"cyan\", \"orange\"]),\n",
    ")\n",
    "\n",
    "# Overlay the dataset points\n",
    "sns.scatterplot(\n",
    "    data=non_separable_dataset,\n",
    "    x=x,\n",
    "    y=y,\n",
    "    hue=\"species\",\n",
    "    ax=ax,\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55d553b-c31e-4d6e-b79f-b5a745070323",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebce6379-a82a-45c9-bee0-cc3a3a542990",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e1755d-58f7-4882-b2d2-210223bf8f3d",
   "metadata": {},
   "source": [
    "Partitions up the feature space using very simple decision rules. For example if is the length $\\leq$ 5.1, or the width is $\\leq$ 1.75."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e1adc0-beb1-4a56-8334-47508c036d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the dataset points\n",
    "ax = sns.scatterplot(\n",
    "    data=non_separable_dataset,\n",
    "    x=x,\n",
    "    y=y,\n",
    "    hue=\"species\",\n",
    ")\n",
    "\n",
    "# Draw horizontal line at y = 1.75\n",
    "ax.axhline(1.75, color=\"gray\", linewidth=3, alpha=0.2)\n",
    "\n",
    "# Draw vertical line at x = 4.95\n",
    "ax.axvline(4.95, color=\"blue\", linewidth=3, alpha=0.2, ymax=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93d941c-7de4-421c-8afa-18bcd2178a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model = tree.DecisionTreeClassifier(max_depth=2, min_impurity_decrease=0.01).fit(\n",
    "    non_separable_dataset[[x, y]],\n",
    "    non_separable_dataset[\"species\"],\n",
    ")\n",
    "\n",
    "tree_model.classes_ = tree_model.classes_[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b23c601-ebbd-446a-9f2b-c603a144bac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "tree.plot_tree(\n",
    "    tree_model,\n",
    "    feature_names=[x, y],\n",
    "    class_names=tree_model.classes_,\n",
    "    filled=True,\n",
    "    impurity=False,\n",
    "    label=\"root\",\n",
    "    rounded=True,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "ax.text(0.43, 0.66, \"yes\")\n",
    "ax.text(0.73, 0.66, \"no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cd79d8-6851-4011-b097-916a6d7e9bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a non-linear support vector machine on the non-linearly-separable dataset\n",
    "clf = tree.DecisionTreeClassifier(max_depth=2, min_impurity_decrease=0.01).fit(\n",
    "    non_separable_dataset[[x, y]].values,\n",
    "    non_separable_dataset[\"species\"],\n",
    ")\n",
    "\n",
    "# Plot the decision boundary of the linear classifier\n",
    "ax = plot_decision_boundary(\n",
    "    clf,\n",
    "    x=non_separable_dataset[x],\n",
    "    y=non_separable_dataset[y],\n",
    "    grid_resolution=100,\n",
    "    plot_method=\"contour\",\n",
    "    levels=[0.5],\n",
    ")\n",
    "\n",
    "plot_decision_boundary(\n",
    "    clf,\n",
    "    x=non_separable_dataset[x],\n",
    "    y=non_separable_dataset[y],\n",
    "    grid_resolution=100,\n",
    "    levels=[0, 0.5, 1],\n",
    "    ax=ax,\n",
    "    cmap=ListedColormap([\"cornflowerblue\", \"cyan\", \"orange\"]),\n",
    ")\n",
    "\n",
    "# Overlay the dataset points\n",
    "sns.scatterplot(\n",
    "    data=non_separable_dataset,\n",
    "    x=x,\n",
    "    y=y,\n",
    "    hue=\"species\",\n",
    "    ax=ax,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b1d614-6b4f-4a55-8be4-fb20f97f8fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a non-linear support vector machine on the non-linearly-separable dataset\n",
    "clf = tree.DecisionTreeClassifier(max_depth=4, min_impurity_decrease=0.01).fit(\n",
    "    non_separable_dataset[[x, y]].values,\n",
    "    non_separable_dataset[\"species\"],\n",
    ")\n",
    "\n",
    "# Plot the decision boundary of the linear classifier\n",
    "ax = plot_decision_boundary(\n",
    "    clf,\n",
    "    x=non_separable_dataset[x],\n",
    "    y=non_separable_dataset[y],\n",
    "    grid_resolution=100,\n",
    "    plot_method=\"contour\",\n",
    "    levels=[0.5],\n",
    ")\n",
    "\n",
    "plot_decision_boundary(\n",
    "    clf,\n",
    "    x=non_separable_dataset[x],\n",
    "    y=non_separable_dataset[y],\n",
    "    grid_resolution=100,\n",
    "    levels=[0, 0.5, 1],\n",
    "    ax=ax,\n",
    "    cmap=ListedColormap([\"cornflowerblue\", \"cyan\", \"orange\"]),\n",
    ")\n",
    "\n",
    "# Overlay the dataset points\n",
    "sns.scatterplot(\n",
    "    data=non_separable_dataset,\n",
    "    x=x,\n",
    "    y=y,\n",
    "    hue=\"species\",\n",
    "    ax=ax,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a35e6ea-3f66-4364-ab34-9f60d7cee862",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "tree.plot_tree(\n",
    "    clf,\n",
    "    feature_names=[x, y],\n",
    "    class_names=clf.classes_,\n",
    "    filled=True,\n",
    "    impurity=False,\n",
    "    label=\"root\",\n",
    "    rounded=True,\n",
    "    ax=ax,\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704941b6-6b3a-4407-a1e5-2842931f2071",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb344229-5079-4a34-a059-e0ce90fa6911",
   "metadata": {},
   "source": [
    "A Random Forest is a collection (or ensemble) of decision trees, where each tree is trained on a different random subset of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321bc814-9a17-49d3-be03-6ebfff03d83d",
   "metadata": {},
   "source": [
    "![Random forest](https://upload.wikimedia.org/wikipedia/commons/7/76/Random_forest_diagram_complete.png)\n",
    "\n",
    "(image taken from the [wikipedia article](https://en.wikipedia.org/wiki/Random_forest) on random forests)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0356b4ae-a786-4496-a671-46cd8e062e26",
   "metadata": {},
   "source": [
    "Wisdom of the crowd!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731e9704-42bd-4c92-ac42-952c456c13ea",
   "metadata": {},
   "source": [
    "Some benefits of RF are:\n",
    "    \n",
    "* Are fast to train and test.\n",
    "* Can deal with noisy features.\n",
    "* Handle features of different units.\n",
    "* Can cope with large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e163be-8157-4ba2-b667-1fe7d695d557",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f42b7c02-258d-4566-aef7-2199f0db0332",
   "metadata": {},
   "source": [
    "## Random Forest on Butterfly dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ccf78d-6d4d-4caa-955a-d3db3312edf3",
   "metadata": {},
   "source": [
    "Here we will split our training data into a training and validation sets and compute classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3737d544-ece5-4d42-8b70-39c8b7036352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# load the scikit learn package\n",
    "import sklearn\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a9fc45-2732-4682-91ee-60081b4bb668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from csv file\n",
    "butterflies = pd.read_csv(\"data/butterflies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db6b672-1472-4e29-b07e-924536a0ef14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the dataset\n",
    "sns.scatterplot(data=butterflies, x=\"Width\", y=\"Height\", hue=\"Species\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35968aca-e25b-483d-aa52-f8e543ed8b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into validation and test\n",
    "# randomly choose take 50 datapoints for validation\n",
    "train_data, validation_data = model_selection.train_test_split(\n",
    "    butterflies, test_size=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221c8f63-f67e-495a-8225-13f28a0c45f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of training samples: \", len(train_data))\n",
    "print(\"Number of validation samples: \", len(validation_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dd12cf-7865-46da-ae6c-5234465d3ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw the dataset\n",
    "sns.scatterplot(data=butterflies, x=\"Width\", y=\"Height\", hue=\"Species\")\n",
    "\n",
    "# with circles around the training set\n",
    "sns.scatterplot(\n",
    "    data=train_data,\n",
    "    x=\"Width\",\n",
    "    y=\"Height\",\n",
    "    marker=\"o\",\n",
    "    edgecolor=\"black\",\n",
    "    facecolor=\"none\",\n",
    "    label=\"train set\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05b0e98-f327-4edc-b609-af1e9a4ed496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the classifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(train_data[[\"Width\", \"Height\"]], train_data[\"Species\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a788eac-8c7d-42ef-a37c-30b9a46c38e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for the validation set\n",
    "species_prediction = rf.predict(validation_data[[\"Width\", \"Height\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f5d109-bdeb-49a2-ac3a-ebdf156b1d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the classification accuracy on the validation set\n",
    "correct_classifications = validation_data[\"Species\"] == species_prediction\n",
    "percent_correct_predictions = correct_classifications.mean() * 100\n",
    "percent_incorrect_predictions = (1 - correct_classifications).mean() * 100\n",
    "print(\"Classification accuracy (%):\", percent_correct_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388308c9-65a3-472a-a7d0-5fc7cdefd2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the incorrect predictions so we can plot them\n",
    "incorrect_predictions = validation_data[~correct_classifications]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bb147f-2b1c-4f29-a5e7-b7adf4489698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw the dataset\n",
    "sns.scatterplot(data=butterflies, x=\"Width\", y=\"Height\", hue=\"Species\")\n",
    "\n",
    "# with circles around the training set\n",
    "sns.scatterplot(\n",
    "    data=train_data,\n",
    "    x=\"Width\",\n",
    "    y=\"Height\",\n",
    "    marker=\"o\",\n",
    "    edgecolor=\"black\",\n",
    "    facecolor=\"none\",\n",
    "    label=\"train data\",\n",
    ")\n",
    "\n",
    "# draw an 'x' where we predict the wrong answer\n",
    "sns.scatterplot(\n",
    "    data=incorrect_predictions,\n",
    "    x=\"Width\",\n",
    "    y=\"Height\",\n",
    "    marker=\"x\",\n",
    "    color=\"black\",\n",
    "    label=\"incorrect predictions\",\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49dfdf0-efc5-41f3-908f-ba071efac9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a non-linear support vector machine on the non-linearly-separable dataset\n",
    "clf = RandomForestClassifier().fit(\n",
    "    non_separable_dataset[[x, y]].values,\n",
    "    non_separable_dataset[\"species\"],\n",
    ")\n",
    "\n",
    "# Plot the decision boundary of the linear classifier\n",
    "ax = plot_decision_boundary(\n",
    "    clf,\n",
    "    x=non_separable_dataset[x],\n",
    "    y=non_separable_dataset[y],\n",
    "    grid_resolution=100,\n",
    "    plot_method=\"contour\",\n",
    "    levels=[0.5],\n",
    ")\n",
    "\n",
    "plot_decision_boundary(\n",
    "    clf,\n",
    "    x=non_separable_dataset[x],\n",
    "    y=non_separable_dataset[y],\n",
    "    grid_resolution=100,\n",
    "    levels=[0, 0.5, 1],\n",
    "    ax=ax,\n",
    "    cmap=ListedColormap([\"cornflowerblue\", \"cyan\", \"orange\"]),\n",
    ")\n",
    "\n",
    "# Overlay the dataset points\n",
    "sns.scatterplot(\n",
    "    data=non_separable_dataset,\n",
    "    x=x,\n",
    "    y=y,\n",
    "    hue=\"species\",\n",
    "    ax=ax,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206908aa-e521-426c-94a2-5fc1b76bc6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354b4347-6f49-4937-acd4-0bbc34601556",
   "metadata": {},
   "outputs": [],
   "source": [
    "IFrame(\"http://cs.stanford.edu/people/karpathy/svmjs/demo/demoforest.html\", width=1000, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d806fe4a-a5a0-497f-8ace-ad82ffc1cdb3",
   "metadata": {},
   "source": [
    "## Which algorithm to choose?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c21c2c4-e397-4760-b746-f9c52f47f221",
   "metadata": {},
   "source": [
    "Short answer: It depends!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6223a11f-0e2a-441a-a21c-d6872097b15e",
   "metadata": {},
   "source": [
    "No silver bullet, but often it is sensible to first try a Support Vector Machine or Random Forest.\n",
    "\n",
    "This will give you an idea of how separable your data is. The next step is to try different features, and perhaps even collect more training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff574d2-48a7-4081-be3d-0bdb667605f2",
   "metadata": {},
   "source": [
    "## How much data do I need?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c4d6c1-cd00-4fe6-81a3-6dd2b62f7b55",
   "metadata": {},
   "source": [
    "Short answer: It depends!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2889cb-346d-4dff-bcf8-b4d9acc0e417",
   "metadata": {},
   "source": [
    "It depends on how easy it is for your classifier to separate your data. Some problems are relatively easy and donâ€™t require lots of data, others such as species identification in images can require 10,000s."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sci",
   "language": "python",
   "name": "sci"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
