{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60fb7fc2-bf71-4db8-9bb8-28544262847f",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/MScEcologyAndDataScienceUCL/BIOS0032_AI4Environment/blob/main/9_AItoEcologicalModels/AItoEcolMods_wk9_PM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ecaae1-5648-4ec0-bbe1-21d206304b24",
   "metadata": {},
   "source": [
    "# AI for the Environment: from AI to Ecological Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbe006b-5028-4663-8e86-5ef72d346a7c",
   "metadata": {},
   "source": [
    "Rory Gibb & Ella Browning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6abe737-e89a-4ba8-9d00-2ceecda6529e",
   "metadata": {},
   "source": [
    "## Drivers of species occurrence across the Masai Mara using generalised linear (mixed) models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6997f9f-86da-46c5-b19b-416e56308190",
   "metadata": {},
   "source": [
    "Today we're exploring and analysing some camera trap data from the Masai Mara collected as part of the Biome Health project - see the lecture slides for a general summary of the data and the project, and see this morning’s workshop for an introduction to spatial data processing and GIS in R."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becd4e53-3424-44c7-83a6-a84aa2d105c8",
   "metadata": {},
   "source": [
    "The goal of this afternoon’s session is to bring together the spatial data collation, processing and exploration from this morning’s session, with a particular research question, and explore fitting some generalised linear and mixed effects models to investigate the drivers and distribution of our study species (the Cape hare). There will be code snippets with short exercises interspersed, along with some larger extension exercises at the end if you have time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236a0616-113d-4d61-8d99-82ae760a4a0a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a98a1c5-99c6-4035-8f38-6353a7491f00",
   "metadata": {},
   "source": [
    "The following cells will get you ready for the notebook. Make sure to run them before everything else. It might take from 10-15 minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6361f8a-a47a-488c-86a6-df17667a47c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Run the setup script that will download and install all dependencies and data\n",
    "![ ! -f \"setup.sh\" ] && wget https://raw.githubusercontent.com/MScEcologyAndDataScienceUCL/BIOS0032_AI4Environment/main/9_AItoEcologicalModels/setup.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ba5597-3ec2-4e1b-ab16-8ff1999ad49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash setup.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28af916d-424c-4f42-a2e8-876349c1e9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Jupyter extension to create R blocks in our notebooks\n",
    "%reload_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da7cb71-26a9-481e-8a25-0afd0663df74",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%%R\n",
    "# Load all dependencies for this notebook\n",
    "library(dplyr)\n",
    "library(magrittr)\n",
    "library(terra)\n",
    "library(rgdal)\n",
    "library(sf)\n",
    "library(ggplot2)\n",
    "library(lme4)\n",
    "library(MetBrewer)\n",
    "library(tibble)\n",
    "library(tidyr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ea4e33-0931-4c27-9f76-524f5316b038",
   "metadata": {},
   "source": [
    "## Defining our research question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ad231b-091d-450f-ab4a-14b4ea180f0a",
   "metadata": {},
   "source": [
    "Let’s start with a broad question: what is the relationship between level of anthropogenic pressure and spatial occupancy of our focal species?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb61eb4-f83d-4251-a82f-71e827aff6fd",
   "metadata": {},
   "source": [
    "We can define anthropogenic pressure in many ways, but here, let’s focus on agricultural land use and livestock pressure. We might also need to account for other factors that may covary with our drivers of interest and also affect hare presence; here, we’ll look at habitat type (proportion of closed habitat) and distance to the nearest water body."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3cad13-035d-408c-bf99-99c12485f217",
   "metadata": {},
   "source": [
    "## Building a full dataframe of environmental covariates for modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f895dc2-3d8a-498c-9a9d-39eda57d11b0",
   "metadata": {},
   "source": [
    "This morning’s session provided an introduction to the process of combining our ecological survey data with other socio-environmental data from spatial sources. From there, it is possible to combine all those operations into a pipeline to build a full covariates dataframe, that we can then use for modelling. In the solutions, you can see the full code block that we used to produce this dataframe from the raw data (i.e. the sampling locations), but for this worksheet, we will just read in this full processed dataframe for use in our analyses further below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62c61ef-1995-4129-b7b5-c7b8c6b5ac06",
   "metadata": {},
   "source": [
    "## Combining environmental covariates and species detections to create a modelling dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff0c08c-1add-46c9-b66b-e7aa3c571acd",
   "metadata": {},
   "source": [
    "When we store and work with data to provide to most statistical models in R (and other software), we work with long-form dataframes where each row is a single observation. For these camera trap data, “one observation” is one day when the trap was operational and sampling (i.e. 1 observation per day). In the above code block visible in the solutions, we created this dataframe, with a total n=5792 observation days. From extracting environmental infromation from associated rasters, we have several covariates we can consider as ecologically relevant: proportion of closed/semi-closed habitat or agriculture land use within a 250m radius; distance to the nearest water source; and daily maximum temperature. We don’t yet have a livestock grazing pressure covariate - let’s come back to that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b8e555-414b-42f2-8c67-1be80cabfd4c",
   "metadata": {},
   "source": [
    "As we discussed in the lecture, this database has some hierarchical and nested structure within it, which we can look at using the summary and table functions. We can also explore the distributions of our covariates of interest, and whether any of these are correlated with each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e374127d-e0af-48cc-bcc4-c9de2b55e991",
   "metadata": {},
   "source": [
    "Firstly, we’ll read in the data including covariates for each camera trap site and the locations information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963e0533-ac18-4cd8-9bd7-ea354c47681d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# read in covariates per camera trap\n",
    "dd = read.csv(\"./data/kenya/data_processed/BH_CTsite_covariates.csv\")\n",
    "\n",
    "# specify date column as date object\n",
    "dd$Date = as.Date(dd$Date, format=\"%Y-%m-%d\")\n",
    "\n",
    "# locations sf object\n",
    "locs = read.csv(\"./data/kenya/survey/bh_camera_locations.csv\") %>%\n",
    "    sf::st_as_sf(coords = c(\"Longitude\", \"Latitude\"), crs = 4326) %>%\n",
    "    sf::st_transform(locs, crs = \"+proj=utm +zone=36 +south +datum=WGS84 +units=m +no_defs\") %>%\n",
    "    dplyr::filter(CT_site != \"MT34\")\n",
    "\n",
    "# add coordinates columns for XY locations\n",
    "locs = cbind(locs, sf::st_coordinates(locs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758d9d6b-4851-4522-9371-97d36fee2b9c",
   "metadata": {},
   "source": [
    "### Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93920b78-d8b0-48b4-a519-a6e672fb170b",
   "metadata": {},
   "source": [
    "* Explore these data by plotting histograms and scatter plots of our covariates of interest. Try calling `table()` on categorical columns to understand the distribution of data between types or `range()` for continuous data. You can also use `ggplot()` to plot boxplots of covariates of interest across different conservancies. What do you notice? Will all of these covariates be suitable to include in a model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656209fa-0d94-49a5-a0ef-a9c934a56665",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# boxplots of how our covariates are distributed across conservancies\n",
    "dd %>%\n",
    "    tidyr::pivot_longer(\n",
    "        cols = c(\"closed_lc\", \"agri_lc\", \"distance_to_water\", \"popdens_log\", \"precip\"),\n",
    "        names_to=\"covariate\", values_to=\"value\") %>%\n",
    "    ggplot() +\n",
    "    geom_boxplot(aes(factor(Conservancy), value, group=Conservancy, fill=Conservancy)) +\n",
    "    theme_minimal() +\n",
    "    facet_wrap(~covariate, scales=\"free_y\") +\n",
    "    # sets the x-axis text to print at an angle and not overlapping the plot\n",
    "    theme(axis.text.x = element_text(angle = 45, hjust = 0.8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931f8936-5dc0-4ec1-a4c9-e280313989ec",
   "metadata": {},
   "source": [
    "Now we have a dataframe of environmental covariates and a general understanding of how these are distributed across our study area. The next thing we need to do is incorporate the actual survey data from the camera trap images. If you recall, earlier today we summarised those images at the site-level so we could plot them over space, as proportion of days in which the species was detected. This afternoon, because we’re considering each day of sampling as an observation, we need to identify whether our species (Lepus capensis, the Cape hare) was detected at each site and day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f29f0a-6ff0-492d-8df3-ebfc08e0052d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# our species of interest\n",
    "sp = \"hare\"\n",
    "\n",
    "# our camera trap data (n=601 observations of our study species)\n",
    "ctd = read.csv(\"./data/kenya/survey/bh_camera_images_mara.csv\") %>%\n",
    "    dplyr::filter(CT_site %in% locs$CT_site) %>% # ensure sites are in CT location data\n",
    "    dplyr::mutate(Date = as.Date(Date, format=\"%Y-%m-%d\")) %>%\n",
    "    dplyr::filter(Species == sp)\n",
    "\n",
    "# summarise this by site and day\n",
    "# gives a value of 1 for each day where the species was detected (n=417 days)\n",
    "ctd_daily = ctd %>%\n",
    "    dplyr::group_by(CT_site, Date) %>%\n",
    "    dplyr::summarise(\n",
    "        Detected = 1,\n",
    "        Species = \"Cape hare\"\n",
    "    )\n",
    "\n",
    "# left join to our environmental data\n",
    "# (remember, left_join auto-fills non-matches with NA\n",
    "# so we replace these with 0, ie. not detected)\n",
    "dd = dd %>%\n",
    "    dplyr::left_join(ctd_daily) %>%\n",
    "    dplyr::mutate(\n",
    "        Detected = replace(Detected, is.na(Detected), 0),\n",
    "        Species = replace(Species, is.na(Species), \"Cape hare\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb70dff-4596-4501-b003-5d9ebc0dfbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# tabulate overall and by conservancy - 417 positive detections, 5192 non-detections\n",
    "# (8% non-zero - not terrible but definitely quite zero-inflated!)\n",
    "table(dd$Detected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7808ef62-a931-4f3a-8a99-8253d07807fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "table(dd$Conservancy, dd$Detected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931378e1-4ca8-49f8-a452-a2c54d853888",
   "metadata": {},
   "source": [
    "Notably, the agriculture land use covariate doesn’t contain any useful comparative information for our questions, as it doesn’t vary between camera sites. There is agricultural land use around the margins of the study area (you can look at this by calling `plot(hab == 6)`, but because our camera trap network was placed in the conservancies and protected areas, it covers an area of land that is hardly cropped)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c777e174-713a-4280-b1ac-240b6c8480d8",
   "metadata": {},
   "source": [
    "However, one of the major anthropogenic factors in this area is activity and grazing livestock (cattle, sheep and goats). Grazing has potential effects on the plant community composition and consequently resource availability as well as potentially reducing wildlife activity in the areas where livestock are active. So quantifying livestock pressure would be an important dimension of anthropogenic activity to account for."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2661eca7-eb10-4785-a057-eec516a218cb",
   "metadata": {},
   "source": [
    "Fortunately, camera traps also capture many images of livestock, as well as wildlife, so we can return to the tagged image data to calculate a proxy for livestock pressure. Let’s define this at the site-level, as the proportion of surveyed days with livestock detected (a measure of intensity of use by livestock). We could probably do a more rigorous job of defining this metric, but this is fine for this workshop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2be8214-a381-4282-8ae5-6df5ca922f65",
   "metadata": {},
   "source": [
    "### Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f304a43-722c-42c2-8144-4a6c16eaf8b4",
   "metadata": {},
   "source": [
    "* Read in the camera trap image data again and subset to livestock (hint you can modify the code above). For each camera trap site calculate the proportion of sampled days when livestock were detected. Remember from this morning that not all locations and days will necessarily have livestock images, so you will need to calculate the total number of days sampled per camera trap from `bh_camera_samplingeffort.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940601b4-c81c-4c55-86a2-9dc681075353",
   "metadata": {},
   "source": [
    "* Combine the livestock data with the main dataset (`dd`), creating a column called `livestock_occ`. Explore how livestock are distributed across conservancies and over space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da79b64a-a339-47c6-8f3e-c8881109891c",
   "metadata": {},
   "source": [
    "* What do you notice about the spatial pattern of anthropogenic factors, as well as environmental factors - how are these different across the study area? Remember that a foundational aspect of statistical models is that they assume errors are independent, conditional on the model. There definitely seems to be some spatial structure here that we might want to take into account later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6845df6-a96c-414c-8c38-feebbabf6641",
   "metadata": {},
   "source": [
    "(The code for this is contained within the solutions if you get stuck!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd69546-b204-4362-9966-45088d3b1b02",
   "metadata": {},
   "source": [
    "## Fitting a logistic (binomial) regression model to estimate probability of occupancy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7277f1d6-1665-41d9-88fb-e9fb2c6e0936",
   "metadata": {},
   "source": [
    "Let’s revisit our research question and formulate some specific expectations, focusing on the intersection of livestock activity and habitat. We know that hares are commonly found in grassland and pastoral ecosystems, so if habitat suitability for hares is shaped by pastoral activity we might expect a positive relationship with livestock activity. Alternatively, it is possible that areas with very high levels of livestock activity are too frequently disturbed to provide amenable habitat, in which case we might expect hare occurrence to decline where livestock use intensity is highest. So here we have two alternative, plausible hypotheses. Let’s try and answer this question using some generalised linear models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4828235e-9f58-4128-9991-eeb02b692c21",
   "metadata": {},
   "source": [
    "* What type of data are our response data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fa7f12-07cd-4b40-92e1-9e2c1ee2d0af",
   "metadata": {},
   "source": [
    "Binomial ($1$/$0$) response data (the species was detected or not detected). We can model these using a logistic regression model with a binomial likelihood, where we estimate the effect of covariates $X_1 : X_n$ on the log odds of occurrence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55586ff3-9702-4c00-8860-bd34d5790e39",
   "metadata": {},
   "source": [
    "The model would be formulated as:\n",
    "\n",
    "$$Y_i \\sim Bernoulli(p)$$\n",
    "$$\\log\\left(\\frac{p_i}{1 - p_i}\\right) = \\beta_0 + X \\beta_i$$\n",
    "\n",
    "where $\\beta$ is a vector of slope parameters, and $X$ is a matrix of covariates, 1 per parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2c25de-70ac-4de9-9dd4-c9395676e261",
   "metadata": {},
   "source": [
    "Our covariates are notably all on quite different scales of magnitude to each other. Recall that a slope parameter describes the change in $Y$ for a single unit change in $X$. This means that the slope parameter sizes for different covariates will mean different things (e.g. $1$ degree of temperature versus moving from $0$ to $1$ in livestock occupancy). A way to deal with this is to centre and scale covariates to make the estimates comparable - subtract the mean and divide by the SD. This way, slope parameters always describe the change in $Y$ for $1$ standard deviation change in $X$, regardless of what units $X$ was measured in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8f7a79-c370-45c5-a62e-43395de89b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# camera trap data (n=3540 observations of livestock)\n",
    "ctd_liv = read.csv(\"./data/kenya/survey/bh_camera_images_mara.csv\") %>%\n",
    "    dplyr::filter(CT_site %in% locs$CT_site) %>% # ensure sites are in location data\n",
    "    dplyr::mutate(Date = as.Date(Date, format=\"%Y-%m-%d\")) %>%\n",
    "    dplyr::filter(Species == \"livestock\")\n",
    "\n",
    "# calculate number of days detected per site\n",
    "livestock_detections = ctd_liv %>%\n",
    "    dplyr::group_by(CT_site) %>%\n",
    "    dplyr::summarise(num_days_detected = n_distinct(Date))\n",
    "\n",
    "# read in \"sampling effort\" csv and calculate number of days sampled for every camera trap\n",
    "effort = read.csv(\"./data/kenya/survey/bh_camera_samplingeffort.csv\") %>%\n",
    "    dplyr::filter(effort_class == 1) %>%\n",
    "    dplyr::group_by(CT_site) %>%\n",
    "    dplyr::summarise(num_days_sampled = n_distinct(Date))\n",
    "\n",
    "# add livestock detections to the days sampled dataframe\n",
    "# (replacing autofill NAs with 0)\n",
    "livestock_detections = effort %>%\n",
    "    dplyr::left_join(livestock_detections) %>%\n",
    "    dplyr::mutate(\n",
    "        num_days_detected = replace(num_days_detected, is.na(num_days_detected), 0),\n",
    "        livestock_occ = num_days_detected/num_days_sampled) %>%\n",
    "    dplyr::select(CT_site, livestock_occ)\n",
    "\n",
    "# check proportions are all between 0 and 1 (important to check if any bugs)\n",
    "range(livestock_detections$livestock_occ)\n",
    "\n",
    "# add to our full data\n",
    "dd = dd %>% left_join(livestock_detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101472b7-1796-4e24-807e-64a314ce3b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# visualise raw relationship between binary outcome and covariates using boxplots\n",
    "dd %>%\n",
    "    tidyr::pivot_longer(\n",
    "        cols=c(\"closed_lc\", \"livestock_occ\", \"distance_to_water\", \"popdens_log\", \"precip\"),\n",
    "        names_to=\"covariate\",\n",
    "        values_to=\"value\") %>%\n",
    "    ggplot() +\n",
    "    geom_jitter(\n",
    "        aes(factor(Detected), value, group=factor(Detected)),\n",
    "        alpha=0.1,\n",
    "        width=0.5,\n",
    "        size=0.2,\n",
    "        color=\"grey70\") +\n",
    "    geom_boxplot(\n",
    "        aes(factor(Detected), value, group=factor(Detected)),\n",
    "        outlier.shape = NULL,\n",
    "        color=\"coral2\") +\n",
    "    theme_minimal() +\n",
    "    facet_wrap(~covariate, scales=\"free_y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f6d546-96b7-4472-bc57-48cfda940441",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "cols = c(\n",
    "    \"closed_lc\",\n",
    "    \"livestock_occ\",\n",
    "    \"distance_to_water\",\n",
    "    \"popdens_log\",\n",
    "    \"precip\"\n",
    ")\n",
    "\n",
    "# scale our linear covariates for comparability\n",
    "dd[, cols] = apply(dd[, cols], 2, scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b91535-daaf-4cd0-91ff-79c245b10201",
   "metadata": {},
   "source": [
    "We can use the glm function to fit a generalised linear model, defining this formula as $Y \\sim 1 + covariate_1 + covariate_2 + \\dots $, where 1 refers to the intercept, with a binomial likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ac2737-96d6-4da8-ba05-1595b22d0775",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# Fit a logistic regression model with an intercept and a slope for livestock\n",
    "# occurrence (our key predictor of interest)\n",
    "m1 = glm(\n",
    "    Detected ~ 1 + livestock_occ,\n",
    "    family=binomial(link=\"logit\"),\n",
    "    data=dd,\n",
    ")\n",
    "\n",
    "# call summary on the model ; this shows an summary of the model residuals,\n",
    "# and a table of coefficients (fitted model parameters, on the log odds scale)\n",
    "# a strongly positive slope of livestock occurrence with low uncertainty (a low SE)!\n",
    "summary(m1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c43b6ad-8b5a-4404-8f80-86b73115e391",
   "metadata": {},
   "source": [
    "### Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425e31ba-e195-42cf-9873-5b8c56ebe72e",
   "metadata": {},
   "source": [
    "* What other factors might be influencing hare occurrence and also covary with livestock occurrence? It may be important to include these too, in case they explain some of this relationship (we’ll explore this more next week). Fit another model called `m2`, including closed habitat and distance to water as covariates. Call `summary()` and take a look at the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a024267b-4b0d-4921-853b-606f54fee789",
   "metadata": {},
   "source": [
    "Now let’s compare the two models. The code below extracts the fitted paramter estimates and calculates the $95\\%$ confidence intervals and visuliases them. Use this to plot the parameter estimates for `m1` and `m2`. What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b1e0ef-88a4-43f6-8ed7-384598cf017d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# Function to plot coefficients and confience intervals.\n",
    "# The intercept is often at a different scale to the slope parameters\n",
    "# so creates a separate sub-plot for the intercept).\n",
    "\n",
    "plotFixedEffects = function(model) {\n",
    "    \n",
    "    plot = coef(summary(model)) %>% # extract parameters table from fitted model\n",
    "        as.data.frame() %>% # convert to df\n",
    "        tibble::rownames_to_column(var=\"param\") %>% # make a column called \"param\" from the row names\n",
    "        # classify param as either Intercept or Slope\n",
    "        dplyr::mutate(param_type = ifelse(param == \"(Intercept)\", \"Intercept\", \"Slope\")) %>%\n",
    "        dplyr::rename(\"se\"=3) %>% # rename std error variable because easier to work with\n",
    "        ggplot() +\n",
    "        geom_point(aes(param, Estimate), size=3) + # point estimate\n",
    "        # 95% confidence interval (1.96 * standard error)\n",
    "        geom_linerange(aes(param, ymin=Estimate-(1.96*se), ymax=Estimate+(1.96*se))) +\n",
    "        geom_hline(yintercept=0, lty=2) + # horizontal line marking zero (i.e. no effect)\n",
    "        theme_minimal() +\n",
    "        facet_wrap(~param_type, scales=\"free\") + # split plot by parameter type\n",
    "        theme(\n",
    "            axis.text = element_text(size=12),\n",
    "            axis.title = element_text(size=12),\n",
    "            strip.text = element_text(size=14)) +\n",
    "        xlab(\"Parameter\") + ylab(\"Estimate (95% confidence interval)\") +\n",
    "        coord_flip() # flip so the plot is horizontal\n",
    "\n",
    "    return(plot)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86e925c-2eb6-401a-ac0b-0bdf15306369",
   "metadata": {},
   "source": [
    "What does this initial statistical model suggest about the relationship between hare occupancy, grazing and habitat metrics?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b667b894-2c32-4eac-885e-f5f0e1ee8590",
   "metadata": {},
   "source": [
    "It suggests a substantial positive relationship with livestock occurrence, as well as declining occupancy at further distances from water, and increasing in closed habitat. The latter effect seems quite counterintuitive in that we don’t usually think of hares as scrub/forest species. Why might this be? Can you think of some ecological reasons for this relationship?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa164ba-35cb-4f51-81e6-977cd190566a",
   "metadata": {},
   "source": [
    "The next stage is to critique the model. Some questions to keep in mind...\n",
    "\n",
    "* Are there obvious clusters or nested structures in the data that we haven’t accounted for that could be affecting our inferred relationships?\n",
    "*  What do the residuals from the model look like? (i.e. the remaining error not explained by the model)\n",
    "* Are the errors independent from each other - i.e. are there any obvious structures or patterns in the residuals that indicate we are missing something from the model?\n",
    "* Thinking about the dataset, how it was collected and its sampling design, what do you think? Is there anything we are obviously missing?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ea88f0-0140-42c6-94a8-254763f7836b",
   "metadata": {},
   "source": [
    "**The conservancy in which the sampling was carried out!** These are community-level conservancies where the livelihoods and land use patterns might differ substantially enough to affect the ecological com- munity. Also as we saw in our boxplots above, livestock activity is definitely concentrated in the 3 more eastward conservancies with very little in the national park (Mara Triangle), and similarly there is less open habitat in the Mara Triangle - perhaps the apparent relationships are influenced by these differences. Let’s take a look."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb1f65b-3780-44ef-83bb-0ff5bc741565",
   "metadata": {},
   "source": [
    "### Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f91db0-510e-459f-830d-b9ffaa22fb2d",
   "metadata": {},
   "source": [
    "* Add conservancy as a fixed effect to your model and save this model as m3. Has adding this changed the estimates of the slope parameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d57725-b947-4aa0-867c-717013c8f7fe",
   "metadata": {},
   "source": [
    "Note that conservancy is a categorical variable, so here rather than a slope we are effectively estimating how the intercept is different between each level of the categorical variable (i.e. are detections higher or lower in each conservancy?). For a categorical covariate we will be estimating n-1 new parameters (where is the number of levels of the covariate), because one of the categories becomes the intercept (the base factor)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9db4676-64d5-4e58-bc92-e9d4785be9a0",
   "metadata": {},
   "source": [
    "Has including conservancy improved the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71401b2c-bc45-4e21-bbe6-45f414639b37",
   "metadata": {},
   "source": [
    "We’ll explore what we mean by “improved” in more depth in next week’s workshop, but for now we can look at some summary metrics of model goodness-of-fit to understand a bit more about how well the model is fitted to our data. In particular we can easily look at 2 metrics based on the log-likelihood (which maximum likelihood fitting approaches aim to maximise)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f9dfe8-6db6-4c7c-90c4-5191cc3b133a",
   "metadata": {},
   "source": [
    "Firstly, the deviance - a measure of how much of the total variation in the observed data is explained bythe model (lower values = more variation explained = better model). Secondly, the AIC (Akaike Information Criterion), which incorporates both the improvement in log-likelihood provided by including more parameters, while penalising model complexity to avoid models that overfit to the data (lower values = better)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e5360a-ee4d-4900-9b51-3f7063856794",
   "metadata": {},
   "source": [
    "We can also look at the distribution of residuals (the unexplained error not accounted for by the model) to check model assumptions. These plots get tricky to interpret visually for GLMs and especially logistic regression, because our outcome is binary, and different likelihoods make different assumptions about how error is distributed around the expected value (e.g. Poisson regression assumes error is wider with higher expected values; see the lecture slides). There are various ways to calculate residuals that account for different model likelihoods; we won’t dig into this much, but [this is a helpful resource](https://bookdown.org/ltupper/340f21_notes/deviance-and-residuals.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a255db-69a7-43d3-94a9-35be180ce7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# extract fit metrics from the model - are the deviance and AIC lower or higher\n",
    "# in the model including conservancy?\n",
    "metrics = data.frame(\n",
    "    model = c(\"without_conservancy\", \"with_conservancy\"),\n",
    "    deviance = as.numeric(c(deviance(m2), deviance(m3))),\n",
    "    AIC = as.numeric(c(AIC(m2), AIC(m3)))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ab150c-7810-474e-b707-0eb02ee04fd6",
   "metadata": {},
   "source": [
    "The GLM function also gives us a summary of the difference between the null and residual deviance for any model (see table at bottom of `summary()` function). This is the difference between the deviance of the simplest possible model explaining least variation (an intercept only model; the “null deviance”), and the deviance of this model with its covariates (the “residual deviance”). A significant reduction in the residual deviance compared to the null supports the inclusion of covariates in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db1026a-9c12-40f1-be4e-9e12f3881012",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "summary(m3)\n",
    "\n",
    "# plot model fitted (expected) values against deviance residuals\n",
    "# difficult tointerpret visually!\n",
    "plot(\n",
    "    fitted(m3),\n",
    "    resid(m3, \"deviance\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36646a48-dc55-4478-b512-593e60209c64",
   "metadata": {},
   "source": [
    "## Accounting for repeat sampling and clustered sampling using mixed-effects models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75186471-35a8-43f5-bbce-cf2f65421bd5",
   "metadata": {},
   "source": [
    "One thing we haven’t accounted for in the model yet is that we have multiple observations from at the same camera site (i.e. repeat sampling) across multiple rows. **Remember**, the model doesn’t know anything by itself - we have to tell it that these observations on different days come from the same place. Otherwise we are violating the assumption that each observation is independent from all the others! (Certain sites might have higher or lower occurrence of hares because of something we haven’t measured, which could bias our model results)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91accb73-71c9-4156-ba27-fd009e8b4f1b",
   "metadata": {},
   "source": [
    "One way we could account for this is to include site as a categorical covariate, which would involve fitting a different individual beta parameter for each site - n=175! That’s a lot of parameters to estimate and uses up a lot of degrees of freedom in the model (i.e. it is gobbling up a lot of information that could be used to infer other parameters)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e72050d-d7fe-48eb-8e9d-32ffe9ad1239",
   "metadata": {},
   "source": [
    "An alternative would be to fit a mixed-effects (multilevel/hierarchical) model where, rather than assuming each site is its own completely independent entity, we instead assume that each site has its own intercept, and that these intercepts are realisations of an underlying population that is described by a normal distribution with some variance (sigma). A large sigma would mean that there is a lot of variation among sites in hare occupancy; a low sigma would mean that all the sites are actually quite similar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c32887e-ec54-4a4e-b257-92fe2287b212",
   "metadata": {},
   "source": [
    "As we saw in the lecture, the model structure would look like this, with $\\alpha_s$ being $175$ parameters, $1$ for each site.\n",
    "\n",
    "$$Y_i \\sim Bernoulli(p_i)$$\n",
    "$$\\log\\left(\\frac{p_i}{1 - p_i}\\right) = \\beta_0 + X\\beta_i + \\alpha_s$$\n",
    "$$\\alpha_s \\sim N(0, \\sigma_s)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f164750-1fbe-4ff8-917a-eb1afa84ef30",
   "metadata": {},
   "source": [
    "Here, we are assuming that a normal distribution can describe this range of intercepts at site-level. What is nice about this approach is that, by assuming each site is an independent realisation of an underlying process described by the $N(0, \\sigma_s)$, the underlying normal distribution model acts as a constraint to avoid the model overfitting parameters to any individual site. So we use up fewer degrees of freedom, and we pool information from across sites to learn something about how variable they are (the sigma, $\\sigma$, parameter). (We are still treating each site as independent from the others, though - keep this in mind, as it will be important we when we get to spatial models next week!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2613561-a37c-42bb-b3a3-7f2f0ce71221",
   "metadata": {},
   "source": [
    "Let’s take a look at this in practice. For this we’ll use the `glmer()` function from the *lme4* package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dbe5e6-7ef3-480b-9d68-bf2f7415b7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# approach 1: fit a GLM with CT_site as a fixed effect, i.e. fitting an\n",
    "# independent parameter per camera trapping site\n",
    "# (this might throw an error message)\n",
    "m4 = glm(\n",
    "    Detected ~ 1 + livestock_occ + closed_lc + distance_to_water +\n",
    "               Conservancy + CT_site,\n",
    "    family=binomial(link=\"logit\"),\n",
    "    data=dd)\n",
    "\n",
    "# call summary on the model - yuck, that's a lot of coefficients and an obvious\n",
    "# issue with fitting the model\n",
    "summary(m4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7ab6ce-780a-49ec-bb97-95c139d320e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# approach 2: define our site as a random intercept within a mixed-effects model\n",
    "# we define a random intercept in the formula as \"+ (1|covariate)\"\n",
    "m5 = lme4::glmer(\n",
    "    Detected ~ 1 + livestock_occ + closed_lc + distance_to_water +\n",
    "               Conservancy + (1|CT_site),\n",
    "    family=binomial(link=\"logit\"),\n",
    "    data=dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f4c354-ec02-4795-9a24-324129adf86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# call summary on m5\n",
    "# now, as well as our intercept and slope parameters (fixed effects), we also\n",
    "# have a random effects table which shows our sigma parameter (it shows both the\n",
    "# variance and sd, i.e. sqrt(variance))\n",
    "# What does this suggest about between-site variability in hare occurrence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a92881-62c2-465b-b4f9-26ee33249946",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# extract and plot the fitted random intercepts for our sites\n",
    "# we can see which sites have particularly high occurrence probabilities\n",
    "# (high positive values) or low (strongly negative values)\n",
    "site_ranefs = ranef(m5)$CT_site %>%\n",
    "    as.data.frame() %>%\n",
    "    tibble::rownames_to_column(var=\"CT_site\") %>%\n",
    "    dplyr::rename(\"Random_intercept\"=2)\n",
    "\n",
    "site_ranefs %>%\n",
    "    ggplot() +\n",
    "    geom_point(aes(CT_site, Random_intercept)) +\n",
    "    geom_hline(yintercept=0) +\n",
    "    theme_minimal() +\n",
    "    ylab(\"Random intercept (log odds scale)\") +\n",
    "    coord_flip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286ea076-85b7-4b7e-a4d1-e9f30347732e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# TODO: Load hab map also\n",
    "# we can map these too - which sites have higher or lower occurrence than expected\n",
    "# conditional on all the other model components?\n",
    "hab_df = as.data.frame(hab, xy=TRUE)\n",
    "locs2 = left_join(locs, site_ranefs)\n",
    "\n",
    "ggplot() +\n",
    "    geom_raster(data = hab_df, aes(x, y, fill=factor(habitatfinal))) +\n",
    "    geom_sf(data=locs2, color=\"black\", aes(size=Random_intercept), alpha=0.6) +\n",
    "    scale_fill_discrete(\n",
    "        type = as.vector(MetBrewer::met.brewer(name=\"Archambault\", n=6)),\n",
    "        name=\"Habitat\") +\n",
    "    theme_classic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81aab21a-1184-42fd-a20f-f86959afb579",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# let's look at the fixed effects, now we've accounted for site-level repeat sampling -\n",
    "# has anything changed?\n",
    "plotFixedEffects(m5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198ebc9c-4855-4ffb-9633-83fb98aaa400",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# what about the goodness-of-fit statistics?\n",
    "# compare AIC for the glm without the site effect, and for m5 with\n",
    "# the site effect - what do you notice?\n",
    "summary(m5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2d53d3-14b9-45a7-9cd9-f0b3576168e8",
   "metadata": {},
   "source": [
    "Having fitted our model, it can be useful to visualise its predictions (the expected values) in relation to our study objective. For example, here, if we wanted to visualise where hare occurrence is expected to be highest or lowest, we could map the predicted values at each site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa75fc74-3cff-452a-b0d2-6c4c71980be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# TODO: load hab raster\n",
    "# extract fitted values and calculate the mean fitted value per site\n",
    "# (i.e. mean probabilty of occurrence across all sampled days)\n",
    "site_preds = dd %>%\n",
    "    dplyr::mutate(fitted = fitted(m5)) %>%\n",
    "    dplyr::group_by(CT_site) %>%\n",
    "    dplyr::summarise(fitted_mean = mean(fitted))\n",
    "\n",
    "# map over space\n",
    "hab_df = as.data.frame(hab, xy=TRUE)\n",
    "locs2 = left_join(locs, site_preds)\n",
    "ggplot() +\n",
    "    geom_raster(data = hab_df, aes(x, y, fill=factor(habitatfinal))) +\n",
    "    geom_sf(data=locs2, color=\"black\", aes(size=fitted_mean), alpha=0.6) +\n",
    "    scale_fill_discrete(\n",
    "        type = as.vector(MetBrewer::met.brewer(name=\"Archambault\", n=6)),\n",
    "        name=\"Habitat\") +\n",
    "    theme_classic()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a68a9f-5f89-4adc-9197-f926b357e98c",
   "metadata": {},
   "source": [
    "## Extension Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c2c2db-4e99-4174-88b2-71a229582225",
   "metadata": {},
   "source": [
    "Now we have several exercises to explore the approach we have taken above, focusing on building mixed-effects models of species occurrence across our camera trap network. While you are working through these, think about some of the aspects of the data and sampling process that we have not yet taken into account."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a3ff8b-05ee-4b3e-8994-e9c6daac8f6a",
   "metadata": {},
   "source": [
    "These might include...\n",
    "* Imperfect species detection and what’s driving it\n",
    "* Species behaviour over space\n",
    "* Unmeasured local factors (what didn’t we measure?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51efa779-eaa4-49b5-8a8b-0b98641e49cd",
   "metadata": {},
   "source": [
    "### Exercise 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f91fb61-6681-4413-96c7-52744473a020",
   "metadata": {},
   "source": [
    "Another dimension of the sampling we haven’t taken into account yet in the model is the temporal dimension. Perhaps there were particular days when our species was particularly active (e.g. because of weather, or seasonal behaviour trends)? Explore variation in detections among dates, and try incorporating date as a random intercept into the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584e32c8-3162-4672-8635-171133420e55",
   "metadata": {},
   "source": [
    "* Does this improve model fit, and if so, does it change our findings? Is there any evidence that including the date of sampling is substantially affecting our inference?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6a1fe2-3adf-43ff-ada4-306af98d68f1",
   "metadata": {},
   "source": [
    "### Exercise 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd11c72-0433-4f4f-8719-7d8133eb41ac",
   "metadata": {},
   "source": [
    "We could also explore whether weather affects our species’ probability of occurrence. The dataframe contains an estimate of local daily precipitation, extracted from the ERA5 reanalysis dataset for the study time period. Plot this against date to look at how much this varies across the time period, then try including this as a covariate in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45aa8df1-6db9-4fe4-9e40-105399b11ab7",
   "metadata": {},
   "source": [
    "* *Think:* what would we causally expect precipitation to act on, the true species occupancy, or our likelihood of detecting it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95333b54-6692-4943-ac0b-a250039526bc",
   "metadata": {},
   "source": [
    "### Exercise 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a673833-cc3a-4c06-b910-b1e17f7e9012",
   "metadata": {},
   "source": [
    "There are several other wildlife species included in the camera trap tagged images data frame. Try developing your own models and hypotheses based on these other species data and our available environmental and social covariates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b0d7e7-1278-4e3b-b5ca-cba5642716a8",
   "metadata": {},
   "source": [
    "* How different are your findings for different species? Are there any consistent patterns?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20c719b-e007-435d-ad98-674fb7973ee2",
   "metadata": {},
   "source": [
    "### Exercise 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f070c4a9-34fa-4512-a678-fe5fd9deb251",
   "metadata": {},
   "source": [
    "Explore the sensitivity of your results to varying other aspects of the models. In particular, the most appropriate size of the buffer zone to calculate habitat or human population density might be different between different species (e.g. between wide- and narrow-ranging species), and we might want to explore whether this affects our findings."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "python",
   "name": "r"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
